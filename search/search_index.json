{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"IBM Sustainability Software Portfolio Connectors Overview Enable automated synchronization of portfolio data between TRIRIGA and Maximo Asset Management systems to integrate asset and facility management operations. Installing App Connect These code patterns utilize App Connect to transfer & transform data. To create a proof of concept, go here and spin up a free instance. For MAS or TAS customers, see the docs here about installing the operator or request an instance through your IBM SRE contact.","title":"Home"},{"location":"#ibm-sustainability-software-portfolio-connectors","text":"","title":"IBM Sustainability Software Portfolio Connectors"},{"location":"#overview","text":"Enable automated synchronization of portfolio data between TRIRIGA and Maximo Asset Management systems to integrate asset and facility management operations.","title":"Overview"},{"location":"#installing-app-connect","text":"These code patterns utilize App Connect to transfer & transform data. To create a proof of concept, go here and spin up a free instance. For MAS or TAS customers, see the docs here about installing the operator or request an instance through your IBM SRE contact.","title":"Installing App Connect"},{"location":"mas-tas-home/","text":"IBM MAS Connector for TRIRIGA Overview Portfolio Data is able to be synced bi-directionally across Maximo & TRIRIGA with the use of these integrations. The data that is supported at this time includes People, Assets, Locations/Spaces, Service Requests, and Work Orders/Work Tasks. After configuring the environments with the proper prerequisites, please select the desired connector below and follow the instructions to implement the integration. Prerequisites These code patterns all require initial configuration of an instance of Maximo, App Connect, and TRIRIGA. These pre-requisites are also assuming that all three applications are behind the same firewall. If any of these three applications do not share the same firewall, a secure connection between the applications will need to be established. IBM does provide a product that accomplishes this- Secure Gateway. Learn more about getting started with Secure Gateway here See below for the pre-requisites of each system: Maximo Credentials and access to an instance of Maximo as well as the WebSphere application which hosts Maximo are required. This code pattern has been tested on Maximo 7.6.1.2 as well as MAS 8.6 The following steps and pre-requisites are done against a Maximo demo database. The naming conventions may slightly differ from this, but these are the necessary components. Within Maximo, configure your instance to be ready to receive records from TRIRIGA. If these pre-requisites are not completed, the action will not be recorded. 1. Create an Organization named TRIRIGA Navigate to the 'Organizations' page and click the blue + button on the top row. Fill in the Organization name with TRIRIGA and the description as \"TRIRIGA Organization\". Fill in the remaining required fields as such Base Currency 1: USD Item Set: SET1 Company Set: COMPSET1 Default Item Status: PENDING Default Stock Category: STK Click Save Organization on the left side of the screen under Common Actions. This will be set to Active later once there is a clearing account. 2. Create a Testing clearing account in Chart of Accounts Navigate to Financial -> Chart of Accounts and click on the previously created TRIRIGA org in the Organizations table. Currently, there should be no GL Accounts for TRIRIGA present Click 'GL Component Maintenance' on the left side under More Actions and add a New Row with the following values: GL Component Value: 1001 Description: Testing Active?: Yes Click OK. Click New Row under GL Accounts for TRIRIGA and click the magnifying glass to search for that GL Component. Select it and it should populate in the GL Account & Description fields. The Active Date field should auto populate to the current date. Now that this account is present, head back to Organizations and update the TRIRIGA organization to show the just created Clearing Account, tick the Active box, and click Save Organization. 3. Create a site TRIMAIN and set it to active On the Organization page, click on the 'Sites' tab at the top of the page. Click New Row under 'Sites' and enter TRIMAIN for Site and \"MAIN Site\" for Description. Set the site to Active. Click Save Organization. 4. Create the PLUSTTRIRIGA External System Navigate to Integration -> External Systems and click on the blue plus button at the top of the page. Under the System name fill in PLUSTTRIRIGA and in the Description fill in \"To integrate Maximo with TRIRIGA\" Enable the System and then fill in the Queues on the right hand side as follows: Outbound Sequential Queue: jms/maximo/int/queues/sqout Inbound Sequential Queue: jms/maximo/int/queues/sqin Inbound Continuous Queue: jms/maximo/int/queues/cqin Save the External System 5. Create the Publish Channels for each integration Navigate to Integration -> Publish Channels For Asset Search for 'MXASSETInterface' under the Publish Channel field. Click on the channel and from the left side of the screen select 'Duplicate Publish Channel' Rename the channel PLUSTMXASSETInterface Click on 'Enable Event Listener' on the left side under More Actions Make sure Publish JSON and Retain MBO's are checked, the Operation should default to Publish and the Adapter should default to MAXIMO. Click 'Save Publish Channel' on the left under Common Actions For Location Search for 'MXOPERLOCInterface' under the Publish Channel field. Click on the channel and from the left side of the screen select 'Duplicate Publish Channel' Rename the channel PLUSTMXOPERLOCInterface Click on 'Enable Event Listener' on the left side under More Actions Make sure Publish JSON and Retain MBO's are checked, the Operation should default to Publish and the Adapter should default to MAXIMO. Click 'Save Publish Channel' on the left under Common Actions For Person Search for 'MXPERSONInterface' under the Publish Channel field. Click on the channel and from the left side of the screen select 'Duplicate Publish Channel' Rename the channel PLUSTMXPERSONInterface Click on 'Enable Event Listener' on the left side under More Actions Make sure Publish JSON and Retain MBO's are checked, the Operation should default to Publish and the Adapter should default to MAXIMO. Click 'Save Publish Channel' on the left under Common Actions 6. Create the Enterprise Services for each integration Navigate to Integration -> Enterprise Services and click on the blue plus button at the top of the page For Asset Under the System name fill in PLUSTMXASSETInterface and in the Description fill in \"ASSETS\" Select 'MXASSET' under Object Structure which will populate the Object Structure Sub-Records table Click 'Save Enterprise Service' on the left under Common Actions For Location Under the System name fill in PLUSTMXOPERLOCInterface and in the Description fill in \"OPERATION LOCATION\" Select 'MXOPERLOC' under Object Structure which will populate the Object Structure Sub-Records table Click 'Save Enterprise Service' on the left under Common Actions For Person Under the System name fill in PLUSTMXPERSONInterface and in the Description fill in \"PERSON\" Select 'MXPERSON' under Object Structure which will populate the Object Structure Sub-Records table Click 'Save Enterprise Service' on the left under Common Actions 7. Create the End Points for each integration Navigate to Integration -> End Points and click on the blue plus button at the top of the page For Asset Under End Point fill in PLUSTASSET and in the Description fill in \"AppConnect ASSET outbound to TRIRIGA\" Select 'HTTP' for Handler Click on 'Save End Point' on the left side under More Actions which will populate the Properties for the End Point Until the flows have a destination url, we can only fill in certain fields: HEADERS: \"Content-Type: application/json\" HTTPMETHOD: POST Save the End Point For Location Under End Point fill in PLUSTLOCATION and in the Description fill in \"AppConnect LOCATION outbound to TRIRIGA\" Select 'HTTP' for Handler Click on 'Save End Point' on the left side under More Actions which will populate the Properties for the End Point Until the flows have a destination url, we can only fill in certain fields: HEADERS: \"Content-Type: application/json\" HTTPMETHOD: POST Save the End Point For Person Under End Point fill in PLUSTPERSON and in the Description fill in \"AppConnect PERSON outbound to TRIRIGA\" Select 'HTTP' for Handler Click on 'Save End Point' on the left side under More Actions which will populate the Properties for the End Point Until the flows have a destination url, we can only fill in certain fields: HEADERS: \"Content-Type: application/json\" HTTPMETHOD: POST Save the End Point 8. Link the Publish Channels & Enterprise Services to the PLUSTTRIRIGA External System On the External Systems page, search and select PLUSTTRIRIGA. Switch over to the Publish Channels tab. One at a time, click New Row and select the Publish Channel for the just created integrations. Make sure the Publish Channel name matches the End Point and it is Enabled like the below image: Once finished, the linked Publish Channels should look like the table below: Channel Description Adaptor End Point User Defined Enabled PLUSTMXASSETInterface ASSETS MAXIMO PLUSTASSET Yes Yes PLUSTMXOPERLOCInterface OPERATION LOCATION MAXIMO PLUSTLOCATION Yes Yes PLUSTMXPERSONInterface PERSON MAXIMO PLUSTPERSON Yes Yes Save the External System Switch over to the Enterprise Services tab. One at a time, click New Row and select the Enterprise Service for the integrations you just created. It should look similar to the below image: When you have finished, your linked Enterprise Services should look like the table below: Service Description Adaptor Operation User Defined Enabled Use Continuous Queue? PLUSTMXASSETInterface ASSETS MAXIMO Sync Yes Yes Yes PLUSTMXOPERLOCInterface OPERATION LOCATION MAXIMO Sync Yes Yes Yes PLUSTMXPERSONInterface PERSON MAXIMO Sync Yes Yes Yes Save the External System 9a. API Key (Maximo-X) First, check to see if the version of Maximo comes with Maximo-X. Navigate to Administration -> Administration and a new tab/window should open with the Maximo-x application. If there is trouble reaching this page or it is not installed, follow 9b in order to create an API key. You should be on a page titled 'Integration'. Click on the tab at the top of the page that says API Keys and click on the button with the blue plus sign that reads 'Add API key' Select user 'MXINTADM' and click the Add button to generate an API key for this user. Securely store this API key for later use. 9b. API Key (No Maximo-X) Follow the steps in this documentation to generate an API key for the user 10. Integration Controls There should be 5 Integration Controls created with the following associations: Integration Control MAXIMO Value External Value Description Domain PLUSTLOCSTATUS ACTIVE ACTIVE Tririga Location Status mapping for inbound flows LOCASSETSTATUS \"\" INACTIVE REVIEW IN PROGRESS N/A N/A \"\" OPERATING OPERATING N/A N/A PLUSTORG TRIMAIN IBM Organization mapping for Tririga N/A \"\" TRIRIGA TRIRIGA N/A N/A PLUSTORGEN TRIRIGA EAGLENA Tririga Organization mapping for Inbound flow N/A \"\" TRIRIGA IBM N/A N/A \"\" TRIRIGA MAXIMO ORG N/A N/A \"\" TRIRIGA TEST N/A N/A \"\" TRIRIGA TRIRIGA N/A N/A PLUSTPRIORITY 1 High Priority mapping for Tririga N/A \"\" 2 Medium N/A N/A \"\" 3 Low N/A N/A PLUSTSITEEN TRIMAIN BEDFORD Tririga Location mapping for inbound flows N/A \"\" TRIMAIN SPACE 01 N/A N/A \"\" TRIMAIN TEST N/A N/A \"\" TRIMAIN TRIMAIN N/A N/A Once these Integration Controls are created, associate them in both the created Enterprise Services and Publish Channels by using the following two tables Enterprise Service Control PLUSTMXASSETInterface PLUSTORGEN \"\" PLUSTPRIORITY \"\" PLUSTSITEEN PLUSTMXOPERLOCInterface PLUSTLOCSTATUS \"\" PLUSTSITEEN \"\" PLUSTSTATUS PLUSTMXPERSONInterface PLUSTORGEN \"\" PLUSTSITEEN Publish Channel Control PLUSTMXASSETInterface PLUSTPRIORITY PLUSTMXOPERLOCInterface N/A PLUSTMXPERSONInterface PLUSTORG Return to the PLUSTTRIRIGA External System. On the left side of the External Systems page, select Setup Integration Controls under 'More Actions' and make sure that all 5 Integration Controls are showing as present. App Connect Access to an instance of App Connect with a deployed instance of a Designer is required. This code pattern has been tested with AppConnect version 3.0 Two accounts need to be created from the 'Catalog' tab in order to connect the applications. Once all of the connectors have loaded, type in 'http' to find the HTTP Application. If this is the first account, select 'Connect' to begin setting up the initial HTTP account. If this is not the first account, make sure to take note if there are any other generic account names present because the number of the one created will depend on what has already been created. App Connect creates an account with a generic name in sequential order (Example: if Account 1 and Account 2 are present, the new account will be Account 3). See the below table for credentials: Flow Account Name Username Password API key API location API key name Max -> Tri mxtririga Your TRIRIGA Username Your TRIRIGA Password N/A N/A N/A Tri -> Max trimaximo N/A N/A Your Maximo apikey header apikey Once the account is connected, head back to the HTTP Application on the Catalog page and rename the new account according to the Account Name column in the above table. TRIRIGA Navigate to Tools > Object Migration and import the latest OM Package found here . The Date Time Format field in the user profile must be in UTC. Navigate to Portfolio > People > My Profile and select the user profile that will be triggering the action. The Date Time Format should be in UTC as shown below. Connectors Name Link Portfolio Data Code Pattern Service Request Code Pattern Work Order Code Pattern","title":"Overview"},{"location":"mas-tas-home/#ibm-mas-connector-for-tririga","text":"","title":"IBM MAS Connector for TRIRIGA"},{"location":"mas-tas-home/#overview","text":"Portfolio Data is able to be synced bi-directionally across Maximo & TRIRIGA with the use of these integrations. The data that is supported at this time includes People, Assets, Locations/Spaces, Service Requests, and Work Orders/Work Tasks. After configuring the environments with the proper prerequisites, please select the desired connector below and follow the instructions to implement the integration.","title":"Overview"},{"location":"mas-tas-home/#prerequisites","text":"These code patterns all require initial configuration of an instance of Maximo, App Connect, and TRIRIGA. These pre-requisites are also assuming that all three applications are behind the same firewall. If any of these three applications do not share the same firewall, a secure connection between the applications will need to be established. IBM does provide a product that accomplishes this- Secure Gateway. Learn more about getting started with Secure Gateway here See below for the pre-requisites of each system:","title":"Prerequisites"},{"location":"mas-tas-home/#maximo","text":"Credentials and access to an instance of Maximo as well as the WebSphere application which hosts Maximo are required. This code pattern has been tested on Maximo 7.6.1.2 as well as MAS 8.6 The following steps and pre-requisites are done against a Maximo demo database. The naming conventions may slightly differ from this, but these are the necessary components. Within Maximo, configure your instance to be ready to receive records from TRIRIGA. If these pre-requisites are not completed, the action will not be recorded.","title":"Maximo"},{"location":"mas-tas-home/#1-create-an-organization-named-tririga","text":"Navigate to the 'Organizations' page and click the blue + button on the top row. Fill in the Organization name with TRIRIGA and the description as \"TRIRIGA Organization\". Fill in the remaining required fields as such Base Currency 1: USD Item Set: SET1 Company Set: COMPSET1 Default Item Status: PENDING Default Stock Category: STK Click Save Organization on the left side of the screen under Common Actions. This will be set to Active later once there is a clearing account.","title":"1. Create an Organization named TRIRIGA"},{"location":"mas-tas-home/#2-create-a-testing-clearing-account-in-chart-of-accounts","text":"Navigate to Financial -> Chart of Accounts and click on the previously created TRIRIGA org in the Organizations table. Currently, there should be no GL Accounts for TRIRIGA present Click 'GL Component Maintenance' on the left side under More Actions and add a New Row with the following values: GL Component Value: 1001 Description: Testing Active?: Yes Click OK. Click New Row under GL Accounts for TRIRIGA and click the magnifying glass to search for that GL Component. Select it and it should populate in the GL Account & Description fields. The Active Date field should auto populate to the current date. Now that this account is present, head back to Organizations and update the TRIRIGA organization to show the just created Clearing Account, tick the Active box, and click Save Organization.","title":"2. Create a Testing clearing account in Chart of Accounts"},{"location":"mas-tas-home/#3-create-a-site-trimain-and-set-it-to-active","text":"On the Organization page, click on the 'Sites' tab at the top of the page. Click New Row under 'Sites' and enter TRIMAIN for Site and \"MAIN Site\" for Description. Set the site to Active. Click Save Organization.","title":"3. Create a site TRIMAIN and set it to active"},{"location":"mas-tas-home/#4-create-the-plusttririga-external-system","text":"Navigate to Integration -> External Systems and click on the blue plus button at the top of the page. Under the System name fill in PLUSTTRIRIGA and in the Description fill in \"To integrate Maximo with TRIRIGA\" Enable the System and then fill in the Queues on the right hand side as follows: Outbound Sequential Queue: jms/maximo/int/queues/sqout Inbound Sequential Queue: jms/maximo/int/queues/sqin Inbound Continuous Queue: jms/maximo/int/queues/cqin Save the External System","title":"4. Create the PLUSTTRIRIGA External System"},{"location":"mas-tas-home/#5-create-the-publish-channels-for-each-integration","text":"Navigate to Integration -> Publish Channels For Asset Search for 'MXASSETInterface' under the Publish Channel field. Click on the channel and from the left side of the screen select 'Duplicate Publish Channel' Rename the channel PLUSTMXASSETInterface Click on 'Enable Event Listener' on the left side under More Actions Make sure Publish JSON and Retain MBO's are checked, the Operation should default to Publish and the Adapter should default to MAXIMO. Click 'Save Publish Channel' on the left under Common Actions For Location Search for 'MXOPERLOCInterface' under the Publish Channel field. Click on the channel and from the left side of the screen select 'Duplicate Publish Channel' Rename the channel PLUSTMXOPERLOCInterface Click on 'Enable Event Listener' on the left side under More Actions Make sure Publish JSON and Retain MBO's are checked, the Operation should default to Publish and the Adapter should default to MAXIMO. Click 'Save Publish Channel' on the left under Common Actions For Person Search for 'MXPERSONInterface' under the Publish Channel field. Click on the channel and from the left side of the screen select 'Duplicate Publish Channel' Rename the channel PLUSTMXPERSONInterface Click on 'Enable Event Listener' on the left side under More Actions Make sure Publish JSON and Retain MBO's are checked, the Operation should default to Publish and the Adapter should default to MAXIMO. Click 'Save Publish Channel' on the left under Common Actions","title":"5. Create the Publish Channels for each integration"},{"location":"mas-tas-home/#6-create-the-enterprise-services-for-each-integration","text":"Navigate to Integration -> Enterprise Services and click on the blue plus button at the top of the page For Asset Under the System name fill in PLUSTMXASSETInterface and in the Description fill in \"ASSETS\" Select 'MXASSET' under Object Structure which will populate the Object Structure Sub-Records table Click 'Save Enterprise Service' on the left under Common Actions For Location Under the System name fill in PLUSTMXOPERLOCInterface and in the Description fill in \"OPERATION LOCATION\" Select 'MXOPERLOC' under Object Structure which will populate the Object Structure Sub-Records table Click 'Save Enterprise Service' on the left under Common Actions For Person Under the System name fill in PLUSTMXPERSONInterface and in the Description fill in \"PERSON\" Select 'MXPERSON' under Object Structure which will populate the Object Structure Sub-Records table Click 'Save Enterprise Service' on the left under Common Actions","title":"6. Create the Enterprise Services for each integration"},{"location":"mas-tas-home/#7-create-the-end-points-for-each-integration","text":"Navigate to Integration -> End Points and click on the blue plus button at the top of the page For Asset Under End Point fill in PLUSTASSET and in the Description fill in \"AppConnect ASSET outbound to TRIRIGA\" Select 'HTTP' for Handler Click on 'Save End Point' on the left side under More Actions which will populate the Properties for the End Point Until the flows have a destination url, we can only fill in certain fields: HEADERS: \"Content-Type: application/json\" HTTPMETHOD: POST Save the End Point For Location Under End Point fill in PLUSTLOCATION and in the Description fill in \"AppConnect LOCATION outbound to TRIRIGA\" Select 'HTTP' for Handler Click on 'Save End Point' on the left side under More Actions which will populate the Properties for the End Point Until the flows have a destination url, we can only fill in certain fields: HEADERS: \"Content-Type: application/json\" HTTPMETHOD: POST Save the End Point For Person Under End Point fill in PLUSTPERSON and in the Description fill in \"AppConnect PERSON outbound to TRIRIGA\" Select 'HTTP' for Handler Click on 'Save End Point' on the left side under More Actions which will populate the Properties for the End Point Until the flows have a destination url, we can only fill in certain fields: HEADERS: \"Content-Type: application/json\" HTTPMETHOD: POST Save the End Point","title":"7. Create the End Points for each integration"},{"location":"mas-tas-home/#8-link-the-publish-channels-enterprise-services-to-the-plusttririga-external-system","text":"On the External Systems page, search and select PLUSTTRIRIGA. Switch over to the Publish Channels tab. One at a time, click New Row and select the Publish Channel for the just created integrations. Make sure the Publish Channel name matches the End Point and it is Enabled like the below image: Once finished, the linked Publish Channels should look like the table below: Channel Description Adaptor End Point User Defined Enabled PLUSTMXASSETInterface ASSETS MAXIMO PLUSTASSET Yes Yes PLUSTMXOPERLOCInterface OPERATION LOCATION MAXIMO PLUSTLOCATION Yes Yes PLUSTMXPERSONInterface PERSON MAXIMO PLUSTPERSON Yes Yes Save the External System Switch over to the Enterprise Services tab. One at a time, click New Row and select the Enterprise Service for the integrations you just created. It should look similar to the below image: When you have finished, your linked Enterprise Services should look like the table below: Service Description Adaptor Operation User Defined Enabled Use Continuous Queue? PLUSTMXASSETInterface ASSETS MAXIMO Sync Yes Yes Yes PLUSTMXOPERLOCInterface OPERATION LOCATION MAXIMO Sync Yes Yes Yes PLUSTMXPERSONInterface PERSON MAXIMO Sync Yes Yes Yes Save the External System","title":"8. Link the Publish Channels &amp; Enterprise Services to the PLUSTTRIRIGA External System"},{"location":"mas-tas-home/#9a-api-key-maximo-x","text":"First, check to see if the version of Maximo comes with Maximo-X. Navigate to Administration -> Administration and a new tab/window should open with the Maximo-x application. If there is trouble reaching this page or it is not installed, follow 9b in order to create an API key. You should be on a page titled 'Integration'. Click on the tab at the top of the page that says API Keys and click on the button with the blue plus sign that reads 'Add API key' Select user 'MXINTADM' and click the Add button to generate an API key for this user. Securely store this API key for later use.","title":"9a. API Key (Maximo-X)"},{"location":"mas-tas-home/#9b-api-key-no-maximo-x","text":"Follow the steps in this documentation to generate an API key for the user","title":"9b. API Key (No Maximo-X)"},{"location":"mas-tas-home/#10-integration-controls","text":"There should be 5 Integration Controls created with the following associations: Integration Control MAXIMO Value External Value Description Domain PLUSTLOCSTATUS ACTIVE ACTIVE Tririga Location Status mapping for inbound flows LOCASSETSTATUS \"\" INACTIVE REVIEW IN PROGRESS N/A N/A \"\" OPERATING OPERATING N/A N/A PLUSTORG TRIMAIN IBM Organization mapping for Tririga N/A \"\" TRIRIGA TRIRIGA N/A N/A PLUSTORGEN TRIRIGA EAGLENA Tririga Organization mapping for Inbound flow N/A \"\" TRIRIGA IBM N/A N/A \"\" TRIRIGA MAXIMO ORG N/A N/A \"\" TRIRIGA TEST N/A N/A \"\" TRIRIGA TRIRIGA N/A N/A PLUSTPRIORITY 1 High Priority mapping for Tririga N/A \"\" 2 Medium N/A N/A \"\" 3 Low N/A N/A PLUSTSITEEN TRIMAIN BEDFORD Tririga Location mapping for inbound flows N/A \"\" TRIMAIN SPACE 01 N/A N/A \"\" TRIMAIN TEST N/A N/A \"\" TRIMAIN TRIMAIN N/A N/A Once these Integration Controls are created, associate them in both the created Enterprise Services and Publish Channels by using the following two tables Enterprise Service Control PLUSTMXASSETInterface PLUSTORGEN \"\" PLUSTPRIORITY \"\" PLUSTSITEEN PLUSTMXOPERLOCInterface PLUSTLOCSTATUS \"\" PLUSTSITEEN \"\" PLUSTSTATUS PLUSTMXPERSONInterface PLUSTORGEN \"\" PLUSTSITEEN Publish Channel Control PLUSTMXASSETInterface PLUSTPRIORITY PLUSTMXOPERLOCInterface N/A PLUSTMXPERSONInterface PLUSTORG Return to the PLUSTTRIRIGA External System. On the left side of the External Systems page, select Setup Integration Controls under 'More Actions' and make sure that all 5 Integration Controls are showing as present.","title":"10. Integration Controls"},{"location":"mas-tas-home/#app-connect","text":"Access to an instance of App Connect with a deployed instance of a Designer is required. This code pattern has been tested with AppConnect version 3.0 Two accounts need to be created from the 'Catalog' tab in order to connect the applications. Once all of the connectors have loaded, type in 'http' to find the HTTP Application. If this is the first account, select 'Connect' to begin setting up the initial HTTP account. If this is not the first account, make sure to take note if there are any other generic account names present because the number of the one created will depend on what has already been created. App Connect creates an account with a generic name in sequential order (Example: if Account 1 and Account 2 are present, the new account will be Account 3). See the below table for credentials: Flow Account Name Username Password API key API location API key name Max -> Tri mxtririga Your TRIRIGA Username Your TRIRIGA Password N/A N/A N/A Tri -> Max trimaximo N/A N/A Your Maximo apikey header apikey Once the account is connected, head back to the HTTP Application on the Catalog page and rename the new account according to the Account Name column in the above table.","title":"App Connect"},{"location":"mas-tas-home/#tririga","text":"Navigate to Tools > Object Migration and import the latest OM Package found here . The Date Time Format field in the user profile must be in UTC. Navigate to Portfolio > People > My Profile and select the user profile that will be triggering the action. The Date Time Format should be in UTC as shown below.","title":"TRIRIGA"},{"location":"mas-tas-home/#connectors","text":"Name Link Portfolio Data Code Pattern Service Request Code Pattern Work Order Code Pattern","title":"Connectors"},{"location":"mas-tas/","text":"Portfolio Data Integration Summary Enable automated synchronization of portfolio data between TRIRIGA and Maximo Asset Management systems to integrate asset and facility management operations. Description In this code pattern, learn how to synchronize bi-directional portfolio data of IBM TRIRIGA and IBM Maximo Asset Management using App Connect Designer flows for synchronizing People, Locations, and Assets. Using the provided flows, enable a variety of use cases: from a simple trigger-action integration that updates or populates the records in the other application, to more complex scripted cron jobs that orchestrate these objects into their respective primary system of record. When a record is updated in Maximo Asset Management, it triggers the flow to synchronize with TRIRIGA. (There is also a flow that works in the reverse direction, that works in a similar way.) App Connect sends a request with the updated information through the flow towards the target system (TRIRIGA). A JSON Parser sifts through the request and converts it to an object. Each object that is returned from the JSON Parser goes through Steps 5-8. The data from the object is mapped to the corresponding fields in the target application (TRIRIGA). The newly mapped data is sent to the target application (TRIRIGA) where the record is created or updated. This record is then validated with the original application (Maximo Asset Management) via another Post request. An ID is either created or updated within the original application (Maximo Asset Management). Steps 4-8 are repeated for each object that is present in the original request (Maximo Asset Management). At the end of this process, a Person, Asset, or Location can be sent from Maximo to TRIRIGA and TRIRIGA to Maximo utilizing App Connect. A detailed breakdown of the specific fields being mapped within each flow can be found in this Mapping Document Step 1 - Select an App Connect Flow for deployment Locate the .yaml file for the deployment direction (MX2TRI or TRI2MX) based on the system of record and download to the local machine. From the previous example, use the MX2TRI flow in the Person row. Asset Maximo TRIRIGA Person MX2TRI TRI2MX Asset MX2TRI TRI2MX Location MX2TRI TRI2MX Make sure to check the Mapping Document that the correct fields are being mapped in the selected flow. Step 2 - Import the Selected Flow in App Connect Follow the below steps to import the flow. Import Steps From the App Connect Dashboard, click 'New' and select 'Import Flow' from the drop down menu. Either drag and drop or select the flow for import. In this example, the MX2TRI Person flow will be used. The flow should now be uploaded onto the App Connect instance. From this screen navigate using the 'Edit flow' button to see the individual nodes of this flow. Be sure to select the HTTP account that was configured for Maximo to TRIRIGA for the connector. Click 'Done' on the top right of the screen then click on the three dots in the top right corner and select 'Start API'. Go to the 'Test' tab once it shows that the flow is 'Running' and select the 'POST' option on the left side of the screen. Click on 'Try It' and grab the url and security credentials from this screen for the next step. If your instance of AppConnect is through the cloud, your page will look a bit different The interface is mostly the same, but instead of 'Try It' you'll see a tab called 'Manage' This page contains a few important pieces of information that you'll need to complete the configuration. First, at the top of the page under 'API Info' you'll see a field called 'Route' This is the route for your flow, you'll need to piece this together with the correct path of the flow that you're implementing in order to create the proper flow url. At the bottom of the page is a field called 'Sharing outside of Cloud Foundry organization'. Here is where you will create your apikey for authentication. The on-prem set up uses basic authentication but the cloud configuration uses an apikey to authorize access. Click on 'Create API key and documentation link' Provide a name and it will generate an apikey for you to use with this flow along with a documentation link that looks like the 'Test' page from the on-prem configuration. The end of the url at the top of the page should have the path that will complete the route url. Copy the end of the url that begins with 'tri' and add it to the piece gathered earlier. The 6 character string that precedes the path on the documentation should match the last 6 characters of the route piece from before. Step 3 - Configure Maximo and TRIRIGA instances with App Connect urls Using the credentials from the end of Step 2, populate the instances of Maximo and TRIRIGA with the correct End Points of the recently created flow. Maximo From the main page of Maximo, click the menu icon on the top left and navigate to Integration -> End Points Fill in the properties with the url, username, and password from Step 2 Click the 'Test' button at the bottom right of the screen and send a simple {\"hello\":\"world\"}. With the proper configuration, there will be an expected error that ends with 'Bad Request'. If there is a different error than Bad Request in the Response window, refer to the Troubleshooting section to debug. If the instance is based in the cloud, there is a slight difference in authorization. Since the authorization is with an api key, remove the basic authorization values (USERNAME & PASSWORD) and in the 'HEADERS' field add the following after Content-Type: X-IBM-Client-Id: [apikey from Step 2] Make sure to separate these two values with a comma. It should look something like this: Content-Type: application/json, X-IBM-Client-Id: [apikey] TRIRIGA From the main page of TRIRIGA, click on Tools -> System Setup -> Integration -> Integration Object. Under the 'Name' column, type in 'apic', and select the integration object that pertains to the record that is getting sent. Click on the object and fill in the credentials in the pop-up box. Step 4 - Configure WebSphere Certificates This step makes a test connection to a Secure Sockets Layer (SSL) port and retrieves the signer from the server during the handshake. Websphere Login to the Websphere console that is hosting the Maximo server Click on Security -> SSL certificate & key management. Under 'Related Items' click on 'Key stores and certificates' Click on 'CellDefaultTrustStore' and on the next page under 'Additional Properties' click on 'Signer certificates'. From this page, click on the button that says 'Retrieve from Port' and fill in the required fields using the table below Field Value Host The host from the url in Step 2 Port 443 Alias appconnect Once all three have been entered in, click 'Retrieve signer information' and the information from the url will populate on screen. Click save in the box at the top and then repeat the process for 'NodeDefaultTrustStore' Step 5 - Test the Flow With these 4 steps completed, test the flow with a payload. Head back to the 'Try It' page in the deployed flow (or the documentation page if cloud-based) and scroll down to the bottom of the page under Parameters. In here, fill in mxUrl and triUrl with the urls for the respective applications, generate a test payload to send through the flow and monitor if the information populates in the desired application. If there is a response other than 200 from the Test, refer to Troubleshooting. References Mapping Document Troubleshooting Common errors that arise from App Connect #### Testing the whole flow If there is a 404 Not Found error when trying to test the flow, this could mean that the flow is not running. Double check to make sure the flow shows a green dot and says 'Running' after edits have been made. If there is a 400 Bad Request error when testing the flow, this could mean the wrong account configurations. Double check to make sure the Accounts from the App Connect pre-requisite section are correct. Common errors that arise from Maximo #### Testing the End Point If an error reads \"The response code received from the HTTP request from the endpoint is not successful.\", this is related to the configured End Point. Double check and make sure the values in 'End Points' are correct. Make sure there are no accidental spaces at the beginning or end in the event of the values being copy/pasted. If an error comes back as a 'PKSync error', this is related to the certificates in WebSphere. Double check and confirm that the certificates from Step 4 are correctly configured. Common errors that arise from TRIRIGA Clear OSLC Cache in TRIRIGA Admin Console in case the integrations do not work in intended manner.","title":"Portfolio Data Integration"},{"location":"mas-tas/#portfolio-data-integration","text":"","title":"Portfolio Data Integration"},{"location":"mas-tas/#summary","text":"Enable automated synchronization of portfolio data between TRIRIGA and Maximo Asset Management systems to integrate asset and facility management operations.","title":"Summary"},{"location":"mas-tas/#description","text":"In this code pattern, learn how to synchronize bi-directional portfolio data of IBM TRIRIGA and IBM Maximo Asset Management using App Connect Designer flows for synchronizing People, Locations, and Assets. Using the provided flows, enable a variety of use cases: from a simple trigger-action integration that updates or populates the records in the other application, to more complex scripted cron jobs that orchestrate these objects into their respective primary system of record. When a record is updated in Maximo Asset Management, it triggers the flow to synchronize with TRIRIGA. (There is also a flow that works in the reverse direction, that works in a similar way.) App Connect sends a request with the updated information through the flow towards the target system (TRIRIGA). A JSON Parser sifts through the request and converts it to an object. Each object that is returned from the JSON Parser goes through Steps 5-8. The data from the object is mapped to the corresponding fields in the target application (TRIRIGA). The newly mapped data is sent to the target application (TRIRIGA) where the record is created or updated. This record is then validated with the original application (Maximo Asset Management) via another Post request. An ID is either created or updated within the original application (Maximo Asset Management). Steps 4-8 are repeated for each object that is present in the original request (Maximo Asset Management). At the end of this process, a Person, Asset, or Location can be sent from Maximo to TRIRIGA and TRIRIGA to Maximo utilizing App Connect. A detailed breakdown of the specific fields being mapped within each flow can be found in this Mapping Document","title":"Description"},{"location":"mas-tas/#step-1-select-an-app-connect-flow-for-deployment","text":"Locate the .yaml file for the deployment direction (MX2TRI or TRI2MX) based on the system of record and download to the local machine. From the previous example, use the MX2TRI flow in the Person row. Asset Maximo TRIRIGA Person MX2TRI TRI2MX Asset MX2TRI TRI2MX Location MX2TRI TRI2MX Make sure to check the Mapping Document that the correct fields are being mapped in the selected flow.","title":"Step 1 - Select an App Connect Flow for deployment"},{"location":"mas-tas/#step-2-import-the-selected-flow-in-app-connect","text":"Follow the below steps to import the flow.","title":"Step 2 - Import the Selected Flow in App Connect"},{"location":"mas-tas/#import-steps","text":"From the App Connect Dashboard, click 'New' and select 'Import Flow' from the drop down menu. Either drag and drop or select the flow for import. In this example, the MX2TRI Person flow will be used. The flow should now be uploaded onto the App Connect instance. From this screen navigate using the 'Edit flow' button to see the individual nodes of this flow. Be sure to select the HTTP account that was configured for Maximo to TRIRIGA for the connector. Click 'Done' on the top right of the screen then click on the three dots in the top right corner and select 'Start API'. Go to the 'Test' tab once it shows that the flow is 'Running' and select the 'POST' option on the left side of the screen. Click on 'Try It' and grab the url and security credentials from this screen for the next step. If your instance of AppConnect is through the cloud, your page will look a bit different The interface is mostly the same, but instead of 'Try It' you'll see a tab called 'Manage' This page contains a few important pieces of information that you'll need to complete the configuration. First, at the top of the page under 'API Info' you'll see a field called 'Route' This is the route for your flow, you'll need to piece this together with the correct path of the flow that you're implementing in order to create the proper flow url. At the bottom of the page is a field called 'Sharing outside of Cloud Foundry organization'. Here is where you will create your apikey for authentication. The on-prem set up uses basic authentication but the cloud configuration uses an apikey to authorize access. Click on 'Create API key and documentation link' Provide a name and it will generate an apikey for you to use with this flow along with a documentation link that looks like the 'Test' page from the on-prem configuration. The end of the url at the top of the page should have the path that will complete the route url. Copy the end of the url that begins with 'tri' and add it to the piece gathered earlier. The 6 character string that precedes the path on the documentation should match the last 6 characters of the route piece from before.","title":"Import Steps"},{"location":"mas-tas/#step-3-configure-maximo-and-tririga-instances-with-app-connect-urls","text":"Using the credentials from the end of Step 2, populate the instances of Maximo and TRIRIGA with the correct End Points of the recently created flow.","title":"Step 3 - Configure Maximo and TRIRIGA instances with App Connect urls"},{"location":"mas-tas/#maximo","text":"From the main page of Maximo, click the menu icon on the top left and navigate to Integration -> End Points Fill in the properties with the url, username, and password from Step 2 Click the 'Test' button at the bottom right of the screen and send a simple {\"hello\":\"world\"}. With the proper configuration, there will be an expected error that ends with 'Bad Request'. If there is a different error than Bad Request in the Response window, refer to the Troubleshooting section to debug. If the instance is based in the cloud, there is a slight difference in authorization. Since the authorization is with an api key, remove the basic authorization values (USERNAME & PASSWORD) and in the 'HEADERS' field add the following after Content-Type: X-IBM-Client-Id: [apikey from Step 2] Make sure to separate these two values with a comma. It should look something like this: Content-Type: application/json, X-IBM-Client-Id: [apikey]","title":"Maximo"},{"location":"mas-tas/#tririga","text":"From the main page of TRIRIGA, click on Tools -> System Setup -> Integration -> Integration Object. Under the 'Name' column, type in 'apic', and select the integration object that pertains to the record that is getting sent. Click on the object and fill in the credentials in the pop-up box.","title":"TRIRIGA"},{"location":"mas-tas/#step-4-configure-websphere-certificates","text":"This step makes a test connection to a Secure Sockets Layer (SSL) port and retrieves the signer from the server during the handshake.","title":"Step 4 - Configure WebSphere Certificates"},{"location":"mas-tas/#websphere","text":"Login to the Websphere console that is hosting the Maximo server Click on Security -> SSL certificate & key management. Under 'Related Items' click on 'Key stores and certificates' Click on 'CellDefaultTrustStore' and on the next page under 'Additional Properties' click on 'Signer certificates'. From this page, click on the button that says 'Retrieve from Port' and fill in the required fields using the table below Field Value Host The host from the url in Step 2 Port 443 Alias appconnect Once all three have been entered in, click 'Retrieve signer information' and the information from the url will populate on screen. Click save in the box at the top and then repeat the process for 'NodeDefaultTrustStore'","title":"Websphere"},{"location":"mas-tas/#step-5-test-the-flow","text":"With these 4 steps completed, test the flow with a payload. Head back to the 'Try It' page in the deployed flow (or the documentation page if cloud-based) and scroll down to the bottom of the page under Parameters. In here, fill in mxUrl and triUrl with the urls for the respective applications, generate a test payload to send through the flow and monitor if the information populates in the desired application. If there is a response other than 200 from the Test, refer to Troubleshooting.","title":"Step 5 - Test the Flow"},{"location":"mas-tas/#references","text":"Mapping Document","title":"References"},{"location":"mas-tas/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"mas-tas/#common-errors-that-arise-from-app-connect","text":"#### Testing the whole flow If there is a 404 Not Found error when trying to test the flow, this could mean that the flow is not running. Double check to make sure the flow shows a green dot and says 'Running' after edits have been made. If there is a 400 Bad Request error when testing the flow, this could mean the wrong account configurations. Double check to make sure the Accounts from the App Connect pre-requisite section are correct.","title":"Common errors that arise from App Connect"},{"location":"mas-tas/#common-errors-that-arise-from-maximo","text":"#### Testing the End Point If an error reads \"The response code received from the HTTP request from the endpoint is not successful.\", this is related to the configured End Point. Double check and make sure the values in 'End Points' are correct. Make sure there are no accidental spaces at the beginning or end in the event of the values being copy/pasted. If an error comes back as a 'PKSync error', this is related to the certificates in WebSphere. Double check and confirm that the certificates from Step 4 are correctly configured.","title":"Common errors that arise from Maximo"},{"location":"mas-tas/#common-errors-that-arise-from-tririga","text":"Clear OSLC Cache in TRIRIGA Admin Console in case the integrations do not work in intended manner.","title":"Common errors that arise from TRIRIGA"},{"location":"max-envizi-index/","text":"IBM MAS Connector for Envizi Overview Enable on-demand and scheduled synchronization of Meters & Meter Reading data between Maximo and Envizi systems. Pre-requisites Maximo Configuration Pre-checks on your data Data for Location Meter will not be exported to Envizi if the Unit of Measurement is not configured. The current integration with Envizi only supports the following Units of Measurement for the Location Meter data: Electric Meters GJ kWh MWh Natural Gas Meters GJ MJ kWh m3 mmbtu therms Water Meters litres kliter m3 gallons Service Address must be configured in Location with the below fields for proper functioning of Envizi's features: Street Address City State Post Code Country Latitude Longitude Deploying Maximo Build Within Maximo, the integration provides integration components (via .dbc script files) and Java Classes as part of the solution. These components need to be installed in the customer's Maximo environment. Components and other content created for this integration solution will be identified by names that begin with PLUSZ. Maximo 7.6.1.2+ On the Maximo Admin workstation, overlay the Maximo SMP directory ( /opt/IBM/SMP/maximo ) with the contents from the solution zip file that is provided. This will lay down the Java Classes and .dbc files provided with the solution. Shutdown the MXServer Run UpdateDB command to install the solution components Navigate to /opt/IBM/SMP/maximo/tools/maximo Run ./updatedb.sh Build the Maximo EAR file Navigate to /opt/IBM/SMP/maximo/deployment Run ./buildmaximoear.sh Deploy the new Maximo EAR File on all Maximo servers In WebSphere console, navigate to: Applications->Application types->Websphere enterprise applications Select MAXIMO and then hit \"Update\" button Select \"Browse\" and select the EAR file from Step 4 Hit \"Next\" and accept defaults from all pages After deployment, click on \"Save\" Start the applications and MXServer MAS 8.8+ Navigate to the Admin dashboard of the instance of Manage within MAS. Select the workspace the instance is deployed on and update the configuration. Scroll down to \"Customization\" and link to the location of the .zip file in the field (See here for more details) Click Apply Changes and Manage will update the instance with the customization. Configuring Artifacts Meter Groups Make sure all the Meters that need to sync with Envizi are in the right meter groups: PLUSZ_ELEC - Electric Meters PLUSZ_GAS - Natural Gas Meters PLUSZ_WTR - Water Meters End Points In the Maximo menu, click on Integration > End Points Under the \"End Point\" column, type \"PLUSZ\" and hit enter to search Click on the \"PLUSZEXPORT\" End Point Configure the parameters required to execute the AppConnect flow URL : Full URL to the flow's API as show in AppConnect \"API Documentation Link\" HEADERS : Replace the YourAPIKeyHere with the AppConnect flow's API Key By default the AppConnect flow will be looking for the API key in the X-IBM-Client-Id header If the API Key is 123 , the final value in this field will be X-IBM-Client-Id: 123,Content-Type: application/json Do not remove ,Content-Type:application/json HTTPMETHOD : Do not change the default value POST Click on \"Save End Point\" in \"Common Actions\" on the left side The End Point is now configured AppConnect Configuration Note: You need IBM Cloud AppConnect Professional or Enterprise to run this flow. Note: The names in the screenshots are generic, other instances will not have the same names during setup. Adding Accounts Before importing the flow to AppConnect, add Accounts for SFTP and HTTP connectors. Navigate to Catalog section of the AppConnect instance In the \"Search application\", type name of the connector to add the account for If the AppConnect instance does not have an account for the connector, click on \"Connect\" to create a new account Else, open the account selection drop down, and click on \"Add a new account ...\" Enter the necessary details for the connector For SFTP, it will be the SFTP server and user account. For HTTP, it will be the Authentication Key or username and password needed for Maximo. Click on Connect From the account selection drop down, select the newly created account. e.g., The default name will be Account 2 if you already have Account 1 Click on the kebab menu (three dots) and select \"Rename Account\" Enter an account name and click on \"Rename Account\". This name can now be used by the connector in the flow. Importing the flow Open the Dashboard of the AppConnect instance Click on the \"New\" button and select \"Import Flow\" Browse to the flow's YAML file and click on \"Import\" The flow will now be imported and opened. Configuring the flow to use the right accounts When importing a flow, it is important to check if the flow is using the right accounts for the different connectors. Click on \"Edit Flow\" See if the connectors are using the right accounts. To change the account for any connector, select the connector and click on the dropdown icon next to the Account's name Select the account name that you want to use from the list Creating API Key Click on \"Manage\". Scroll to the bottom of the page. Click on \"Create API key and documentation link\" Enter name for the API key and click on \"Create\" Make a note of this key. Maximo End Point will be configured to send this API key as value for the X-IBM-Client-Id header while calling the AppConnect flow API. Open the \"API Documentation Link\" in another tab. Click on the Route to see the URL Copy the link show in details tab next to the HTTP Method It is helpful to use a tool like Postman to test this API prior to testing it for the first time from Maximo.","title":"Overview"},{"location":"max-envizi-index/#ibm-mas-connector-for-envizi","text":"","title":"IBM MAS Connector for Envizi"},{"location":"max-envizi-index/#overview","text":"Enable on-demand and scheduled synchronization of Meters & Meter Reading data between Maximo and Envizi systems.","title":"Overview"},{"location":"max-envizi-index/#pre-requisites","text":"","title":"Pre-requisites"},{"location":"max-envizi-index/#maximo-configuration","text":"","title":"Maximo Configuration"},{"location":"max-envizi-index/#pre-checks-on-your-data","text":"Data for Location Meter will not be exported to Envizi if the Unit of Measurement is not configured. The current integration with Envizi only supports the following Units of Measurement for the Location Meter data: Electric Meters GJ kWh MWh Natural Gas Meters GJ MJ kWh m3 mmbtu therms Water Meters litres kliter m3 gallons Service Address must be configured in Location with the below fields for proper functioning of Envizi's features: Street Address City State Post Code Country Latitude Longitude","title":"Pre-checks on your data"},{"location":"max-envizi-index/#deploying-maximo-build","text":"Within Maximo, the integration provides integration components (via .dbc script files) and Java Classes as part of the solution. These components need to be installed in the customer's Maximo environment. Components and other content created for this integration solution will be identified by names that begin with PLUSZ.","title":"Deploying Maximo Build"},{"location":"max-envizi-index/#maximo-7612","text":"On the Maximo Admin workstation, overlay the Maximo SMP directory ( /opt/IBM/SMP/maximo ) with the contents from the solution zip file that is provided. This will lay down the Java Classes and .dbc files provided with the solution. Shutdown the MXServer Run UpdateDB command to install the solution components Navigate to /opt/IBM/SMP/maximo/tools/maximo Run ./updatedb.sh Build the Maximo EAR file Navigate to /opt/IBM/SMP/maximo/deployment Run ./buildmaximoear.sh Deploy the new Maximo EAR File on all Maximo servers In WebSphere console, navigate to: Applications->Application types->Websphere enterprise applications Select MAXIMO and then hit \"Update\" button Select \"Browse\" and select the EAR file from Step 4 Hit \"Next\" and accept defaults from all pages After deployment, click on \"Save\" Start the applications and MXServer","title":"Maximo 7.6.1.2+"},{"location":"max-envizi-index/#mas-88","text":"Navigate to the Admin dashboard of the instance of Manage within MAS. Select the workspace the instance is deployed on and update the configuration. Scroll down to \"Customization\" and link to the location of the .zip file in the field (See here for more details) Click Apply Changes and Manage will update the instance with the customization.","title":"MAS 8.8+"},{"location":"max-envizi-index/#configuring-artifacts","text":"","title":"Configuring Artifacts"},{"location":"max-envizi-index/#meter-groups","text":"Make sure all the Meters that need to sync with Envizi are in the right meter groups: PLUSZ_ELEC - Electric Meters PLUSZ_GAS - Natural Gas Meters PLUSZ_WTR - Water Meters","title":"Meter Groups"},{"location":"max-envizi-index/#end-points","text":"In the Maximo menu, click on Integration > End Points Under the \"End Point\" column, type \"PLUSZ\" and hit enter to search Click on the \"PLUSZEXPORT\" End Point Configure the parameters required to execute the AppConnect flow URL : Full URL to the flow's API as show in AppConnect \"API Documentation Link\" HEADERS : Replace the YourAPIKeyHere with the AppConnect flow's API Key By default the AppConnect flow will be looking for the API key in the X-IBM-Client-Id header If the API Key is 123 , the final value in this field will be X-IBM-Client-Id: 123,Content-Type: application/json Do not remove ,Content-Type:application/json HTTPMETHOD : Do not change the default value POST Click on \"Save End Point\" in \"Common Actions\" on the left side The End Point is now configured","title":"End Points"},{"location":"max-envizi-index/#appconnect-configuration","text":"Note: You need IBM Cloud AppConnect Professional or Enterprise to run this flow. Note: The names in the screenshots are generic, other instances will not have the same names during setup.","title":"AppConnect Configuration"},{"location":"max-envizi-index/#adding-accounts","text":"Before importing the flow to AppConnect, add Accounts for SFTP and HTTP connectors. Navigate to Catalog section of the AppConnect instance In the \"Search application\", type name of the connector to add the account for If the AppConnect instance does not have an account for the connector, click on \"Connect\" to create a new account Else, open the account selection drop down, and click on \"Add a new account ...\" Enter the necessary details for the connector For SFTP, it will be the SFTP server and user account. For HTTP, it will be the Authentication Key or username and password needed for Maximo. Click on Connect From the account selection drop down, select the newly created account. e.g., The default name will be Account 2 if you already have Account 1 Click on the kebab menu (three dots) and select \"Rename Account\" Enter an account name and click on \"Rename Account\". This name can now be used by the connector in the flow.","title":"Adding Accounts"},{"location":"max-envizi-index/#importing-the-flow","text":"Open the Dashboard of the AppConnect instance Click on the \"New\" button and select \"Import Flow\" Browse to the flow's YAML file and click on \"Import\" The flow will now be imported and opened.","title":"Importing the flow"},{"location":"max-envizi-index/#configuring-the-flow-to-use-the-right-accounts","text":"When importing a flow, it is important to check if the flow is using the right accounts for the different connectors. Click on \"Edit Flow\" See if the connectors are using the right accounts. To change the account for any connector, select the connector and click on the dropdown icon next to the Account's name Select the account name that you want to use from the list","title":"Configuring the flow to use the right accounts"},{"location":"max-envizi-index/#creating-api-key","text":"Click on \"Manage\". Scroll to the bottom of the page. Click on \"Create API key and documentation link\" Enter name for the API key and click on \"Create\" Make a note of this key. Maximo End Point will be configured to send this API key as value for the X-IBM-Client-Id header while calling the AppConnect flow API. Open the \"API Documentation Link\" in another tab. Click on the Route to see the URL Copy the link show in details tab next to the HTTP Method It is helpful to use a tool like Postman to test this API prior to testing it for the first time from Maximo.","title":"Creating API Key"},{"location":"maximo-envizi/","text":"Maximo - Envizi integration Using the flows Flow included in this integration: PLUSZMXTOSFTP This integration uses the built in Maximo cron tasks. Cron Tasks For every Object Structure that gets pulled out of Maximo and pushed to Envizi, there are two types of Cron jobs: Always-on Cron (Always-Cron) This is for pulling the live or recent data, which is supposed to run frequently. This will pull the data that has come into the system after the last time it ran. Based on its running frequency, the system will automatically decide the window of dates/timestamps to pull the data from. These Cron Task Instances will use the suffix _ALWAYS_ON On-demand Cron (Cron-demand) Even though this is a Cron, this is supposed to run just once, on-demand, when the customer or the user wants to pull data between fixed dates/timestamps. Once the first cron event executes, it should be stopped in order to prevent the same data getting pulled again and again. This is a stop-gap for now as we dont have another way from Maximo to call a preconfigured API on-demand. This might be needed during initial setup of the system, as the Always-on Cron will start pulling data that has arrived after it has been started. This can also be used anytime in the future if there is any need to pull any historical data on-demand. The start date ( OVERRIDESTARTDATE ) and end date ( OVERRIDEENDDATE ) have to be configured before the cron is started. These Cron Task Instances will use the suffix ON_DEMAND Basic Parameters MXURL : The base URL of the Maximo instance. This would include the protocol, domain name and the port number. Do not put a trailing / at the end. In the absense of port number, the default port for the protocol will be used (80 for http, 443 for https) . e.g. http://example.maximo.com:9080 CUSTOMER : Name of the customer. This will be used to name the CSV files. To be supplied by Envizi. OVERRIDESTARTDATE : (Only for On-demand Cron) The start timestamp of the window between which the data will be pulled from. The date must be specified in ISO 8601 format. e.g. 2022-06-26T23:09:30-07:00 where -07:00 represents timezone offset of UTC-07:00 hours OVERRIDEENDDATE : (Only for On-demand Cron) The end timestamp of the window between which the data will be pulled from. The date must be specified in ISO 8601 format. e.g. 2022-06-26T23:09:30-07:00 where -07:00 represents timezone offset of UTC-07:00 hours Advanced Parameters These will be set to the right values by default. DO NOT change these parameters without consulting with Envizi. SELECT : Names of the fields from the Object Structure FROM : Name of the Object Structure WHERE : (Optional). OSLC Condition for data selection ORDERBY : (Optional). Sequence by which the data should be pulled TARGETDATECOLUMN : Name of the DateTime Column in the Object structure that will be used to filter records between a date-time window. SAVEDQUERY ENDPOINTNAME - Name of the Maximo End Point configured to connect to the AppConnect flow. PAGESIZE - Maximum number of records pulled from Maximo in one API call. This will also be the maximum number of records in the CSV file. Configuring Cron Task In the Maximo menu, click on System Configuration > Platform Configuration > Cron Task Setup Under the \"Cron Task\" column, type \"PLUSZ\" and hit enter to search Click on the \"PLUSZEXPORT\" Cron Task In the Cron Task Instances, click on the Schedule/Calendar icon to set the schedule for the Cron Task Instance Once it is configured, click on \"OK\" Select the Cron Task Instance to configure Parameters for Scroll down to the \"Cron Task Parameters\" section and configure the \"Value\" column as needed. Ideally, only the CUSTOMER and MXURL parameters will need to be edited for all instances. For the \"On-demand\" Crons, the OVERRIDESTARTDATE and OVERRIDEENDDATE parameters will need to be edited. Click on Save Start/Stop the Cron Task Instance Navigate inside the Cron Task as mentioned above Enable/Disable the checkbox in the column \"Active?\" in front of the desired Cron Task Instance Click on Save Starting and Stopping the flow If using AppConnect Dashboard, Click on the kebab menu (three dots) on the flow's tile. If inside the flow, Click on the kebab menu (three dots) on top right of the screen. Click on \"Start API\" or \"Stop API\" depending on what action you want to perform. Note: If the flow is not running, AppConnect will give Error 404 on the API call. If Checks for the mandatory fields that are required for the flow to function. If any of the fields are missing, the flow returns Error 400. If 3 Checks the presence of OVERRIDESTARTDATE and OVERRIDEENDDATE in the Request. It also checks if they are valid dates. If all checks are passed, dateQuery with these override dates is generated. If the override date checks fail, it checks if LASTSTARTDATE is present. If it is, dateQuery with it is generated. If all checks fail, the flow returns Error 400 Set variable 5 where : The final oslc.where query created using WHERE from Request and dateQuery from the output of \"If 3\" batchTimestamp : Current Epoc timestamp in milliseconds. This will be included in every filename to indicate that they are from the same batch of exported data. Set variable query : The query to be sent to OSLC API to fetch the required data pagesize : The total number of records that will be fetched in one page. If it is not specified in the request, the flow will use default value of 100 . HTTP Invoke Method Does an HTTP GET to the Maximo's OSLC API to fetch the total number of records that match the query. countonlyparams from \"Set variable\" will be used here. Set variable 2 totalCount : Total Count received in the response of the \"HTTP Invoke Method\" Set variable 3 totalPages : Total number of pages to be fetched from Maximo OSLC API that match the query. This is calculated using the totalCount from \"Set variable 2\" and pagesize from \"Set variable\". For each: page Summary: Fetches data from Maximo OSLC API page by page and writes CSV file to the SFTP server. Input: An array of numbers from 1 to totalPages from \"Set variable 3\" Output: fileWritten - Array of string containing names of files written to the SFTP server. HTTP Invoke method 2 Does an HTTP GET call to Maximo OSLC API to fetch the data that matches queryparams from \"Set variable\" for the current page from \"For each: page\" Set variable 4 filename : File name as per format specified by Envizi team using CUSTOMER and FROM from the Request, batchTimestamp from \"Set variable 5\" and current page from \"For each: page\". eg. DemoCorporation_PLUSZLOCATIONS_1654856600431_1.csv SFTP Create file Writes Response body from \"HTTP Invoke method 2\" to the configured SFTP Server with the filename from \"Set variable 4\" at the preconfigured file path. Response Returns HTTP Status 200 with JSON body containing: - filesWritten : Array of file names written to the SFTP server, obtained from the output of \"For each: page\" - queryparams : query from \"Set variable\" The JSON in response body is not used or stored by Maximo.","title":"IBM Maximo Application Suite Connector for Envizi"},{"location":"maximo-envizi/#maximo-envizi-integration","text":"","title":"Maximo - Envizi integration"},{"location":"maximo-envizi/#using-the-flows","text":"Flow included in this integration: PLUSZMXTOSFTP This integration uses the built in Maximo cron tasks.","title":"Using the flows"},{"location":"maximo-envizi/#cron-tasks","text":"For every Object Structure that gets pulled out of Maximo and pushed to Envizi, there are two types of Cron jobs:","title":"Cron Tasks"},{"location":"maximo-envizi/#always-on-cron-always-cron","text":"This is for pulling the live or recent data, which is supposed to run frequently. This will pull the data that has come into the system after the last time it ran. Based on its running frequency, the system will automatically decide the window of dates/timestamps to pull the data from. These Cron Task Instances will use the suffix _ALWAYS_ON","title":"Always-on Cron (Always-Cron)"},{"location":"maximo-envizi/#on-demand-cron-cron-demand","text":"Even though this is a Cron, this is supposed to run just once, on-demand, when the customer or the user wants to pull data between fixed dates/timestamps. Once the first cron event executes, it should be stopped in order to prevent the same data getting pulled again and again. This is a stop-gap for now as we dont have another way from Maximo to call a preconfigured API on-demand. This might be needed during initial setup of the system, as the Always-on Cron will start pulling data that has arrived after it has been started. This can also be used anytime in the future if there is any need to pull any historical data on-demand. The start date ( OVERRIDESTARTDATE ) and end date ( OVERRIDEENDDATE ) have to be configured before the cron is started. These Cron Task Instances will use the suffix ON_DEMAND","title":"On-demand Cron (Cron-demand)"},{"location":"maximo-envizi/#basic-parameters","text":"MXURL : The base URL of the Maximo instance. This would include the protocol, domain name and the port number. Do not put a trailing / at the end. In the absense of port number, the default port for the protocol will be used (80 for http, 443 for https) . e.g. http://example.maximo.com:9080 CUSTOMER : Name of the customer. This will be used to name the CSV files. To be supplied by Envizi. OVERRIDESTARTDATE : (Only for On-demand Cron) The start timestamp of the window between which the data will be pulled from. The date must be specified in ISO 8601 format. e.g. 2022-06-26T23:09:30-07:00 where -07:00 represents timezone offset of UTC-07:00 hours OVERRIDEENDDATE : (Only for On-demand Cron) The end timestamp of the window between which the data will be pulled from. The date must be specified in ISO 8601 format. e.g. 2022-06-26T23:09:30-07:00 where -07:00 represents timezone offset of UTC-07:00 hours","title":"Basic Parameters"},{"location":"maximo-envizi/#advanced-parameters","text":"These will be set to the right values by default. DO NOT change these parameters without consulting with Envizi. SELECT : Names of the fields from the Object Structure FROM : Name of the Object Structure WHERE : (Optional). OSLC Condition for data selection ORDERBY : (Optional). Sequence by which the data should be pulled TARGETDATECOLUMN : Name of the DateTime Column in the Object structure that will be used to filter records between a date-time window. SAVEDQUERY ENDPOINTNAME - Name of the Maximo End Point configured to connect to the AppConnect flow. PAGESIZE - Maximum number of records pulled from Maximo in one API call. This will also be the maximum number of records in the CSV file.","title":"Advanced Parameters"},{"location":"maximo-envizi/#configuring-cron-task","text":"In the Maximo menu, click on System Configuration > Platform Configuration > Cron Task Setup Under the \"Cron Task\" column, type \"PLUSZ\" and hit enter to search Click on the \"PLUSZEXPORT\" Cron Task In the Cron Task Instances, click on the Schedule/Calendar icon to set the schedule for the Cron Task Instance Once it is configured, click on \"OK\" Select the Cron Task Instance to configure Parameters for Scroll down to the \"Cron Task Parameters\" section and configure the \"Value\" column as needed. Ideally, only the CUSTOMER and MXURL parameters will need to be edited for all instances. For the \"On-demand\" Crons, the OVERRIDESTARTDATE and OVERRIDEENDDATE parameters will need to be edited. Click on Save","title":"Configuring Cron Task"},{"location":"maximo-envizi/#startstop-the-cron-task-instance","text":"Navigate inside the Cron Task as mentioned above Enable/Disable the checkbox in the column \"Active?\" in front of the desired Cron Task Instance Click on Save","title":"Start/Stop the Cron Task Instance"},{"location":"maximo-envizi/#starting-and-stopping-the-flow","text":"If using AppConnect Dashboard, Click on the kebab menu (three dots) on the flow's tile. If inside the flow, Click on the kebab menu (three dots) on top right of the screen. Click on \"Start API\" or \"Stop API\" depending on what action you want to perform. Note: If the flow is not running, AppConnect will give Error 404 on the API call.","title":"Starting and Stopping the flow"},{"location":"maximo-envizi/#if","text":"Checks for the mandatory fields that are required for the flow to function. If any of the fields are missing, the flow returns Error 400.","title":"If"},{"location":"maximo-envizi/#if-3","text":"Checks the presence of OVERRIDESTARTDATE and OVERRIDEENDDATE in the Request. It also checks if they are valid dates. If all checks are passed, dateQuery with these override dates is generated. If the override date checks fail, it checks if LASTSTARTDATE is present. If it is, dateQuery with it is generated. If all checks fail, the flow returns Error 400","title":"If 3"},{"location":"maximo-envizi/#set-variable-5","text":"where : The final oslc.where query created using WHERE from Request and dateQuery from the output of \"If 3\" batchTimestamp : Current Epoc timestamp in milliseconds. This will be included in every filename to indicate that they are from the same batch of exported data.","title":"Set variable 5"},{"location":"maximo-envizi/#set-variable","text":"query : The query to be sent to OSLC API to fetch the required data pagesize : The total number of records that will be fetched in one page. If it is not specified in the request, the flow will use default value of 100 .","title":"Set variable"},{"location":"maximo-envizi/#http-invoke-method","text":"Does an HTTP GET to the Maximo's OSLC API to fetch the total number of records that match the query. countonlyparams from \"Set variable\" will be used here.","title":"HTTP Invoke Method"},{"location":"maximo-envizi/#set-variable-2","text":"totalCount : Total Count received in the response of the \"HTTP Invoke Method\"","title":"Set variable 2"},{"location":"maximo-envizi/#set-variable-3","text":"totalPages : Total number of pages to be fetched from Maximo OSLC API that match the query. This is calculated using the totalCount from \"Set variable 2\" and pagesize from \"Set variable\".","title":"Set variable 3"},{"location":"maximo-envizi/#for-each-page","text":"Summary: Fetches data from Maximo OSLC API page by page and writes CSV file to the SFTP server. Input: An array of numbers from 1 to totalPages from \"Set variable 3\" Output: fileWritten - Array of string containing names of files written to the SFTP server.","title":"For each: page"},{"location":"maximo-envizi/#http-invoke-method-2","text":"Does an HTTP GET call to Maximo OSLC API to fetch the data that matches queryparams from \"Set variable\" for the current page from \"For each: page\"","title":"HTTP Invoke method 2"},{"location":"maximo-envizi/#set-variable-4","text":"filename : File name as per format specified by Envizi team using CUSTOMER and FROM from the Request, batchTimestamp from \"Set variable 5\" and current page from \"For each: page\". eg. DemoCorporation_PLUSZLOCATIONS_1654856600431_1.csv","title":"Set variable 4"},{"location":"maximo-envizi/#sftp-create-file","text":"Writes Response body from \"HTTP Invoke method 2\" to the configured SFTP Server with the filename from \"Set variable 4\" at the preconfigured file path.","title":"SFTP Create file"},{"location":"maximo-envizi/#response","text":"Returns HTTP Status 200 with JSON body containing: - filesWritten : Array of file names written to the SFTP server, obtained from the output of \"For each: page\" - queryparams : query from \"Set variable\" The JSON in response body is not used or stored by Maximo.","title":"Response"},{"location":"service-request/","text":"Service Request Integration Summary Enable automated synchronization of Service Request data from IBM Maximo to IBM TRIRIGA or vice versa. Description In this code pattern, learn how to synchronize a Service Request created in Maximo with TRIRIGA using an AppConnect Designer flow. When a Service Request is created in Maximo Asset Management, it triggers the flow to populate the request in TRIRIGA. (There is also a flow that works in the reverse direction, that works in a similar way.) App Connect sends a request with the new information through the flow towards the target system (TRIRIGA). A JSON Parser sifts through the request and converts it to an object. This object from the JSON Parser goes through Steps 5-8. The data from the object is mapped to the corresponding fields in the target application (TRIRIGA). The newly mapped data is sent to the target application (TRIRIGA) where the request is then created. This record is then validated with the original application (Maximo Asset Management) via another Post request. An ID is created within the original application (Maximo Asset Management). At the end of this process, a Service Request can be created within Maximo and sent to TRIRIGA and vice versa. Pre-requisites This configuration assumes the completion of the pre-requisites and steps outlined in the Maximo <-> TRIRIGA code pattern. See here for those steps. Maximo Within Maximo, some initial changes to the database and Service Request application need to be completed in order for the integration to work properly. Errors may arise if these steps are not completed. 1. Create a Domain that will link to an attribute on the Ticket table. Field Name Value Domain PLUSIREQCLASS Description Tririga service request class Domain Type ALN Data Type ALN Length 10 This domain will need to be populated in order to send a service request out of Maximo. This will be completed in a later step. 2. Head to Database Configuration and search for the 'Ticket' object. Go to 'Attributes' and create a new row: Field Name Value Attribute PLUSIREQCLASSID Description TRIRIGA request class of value Type ALN Length 10 Required No Domain Select the PLUSIREQCLASS Domain from the previous step ** Make sure the length of this attribute has the same length as the domain that is linked Save the attribute. Apply the configuration changes to the database by switching on Admin mode and Apply Database Configuration 3. Configure the Publish Channel, Enterprise Service, End Point, and External System Publish Channel Navigate to Integration -> Publish Channels 1. Search for 'MXSRInterface' under the Publish Channel field. Click on the channel and from the left side of the screen select 'Duplicate Publish Channel' 2. Rename the channel PLUSIMXSR 3. Click on 'Enable Event Listener' on the left side under More Actions 4. Make sure Publish JSON and Retain MBO's are checked, the Operation should default to Publish and the Adapter should default to MAXIMO. 5. Click 'Save Publish Channel' on the left under Common Actions Enterprise Service Navigate to Integration -> Enterprise Services and click on the blue plus button at the top of the page 1. Under the System name fill in PLUSIMXSR and in the Description fill in \"SERVICE REQUEST\" 2. Select 'MXSR' under Object Structure which will populate the Object Structure Sub-Records table 3. Click 'Save Enterprise Service' on the left under Common Actions Repeat this sequence for PLUSISRDOMAIN. In Description fill in \"Service Request class records from Tririga\" and select 'MXDOMAIN' for the Object Structure. End Point Navigate to Integration -> End Points and click on the blue plus bitton at the top of the page 1. Under End Point fill in PLUSISREQ and in the Description fill in \"AppConnect SERVICE REQUEST outbound to TRIRIGA\" 2. Select 'HTTP' for Handler 3. Click on 'Save End Point' on the left side under More Actions which will populate the Properties for the End Point 4. Until the flows have a destination url, we can only fill in certain fields: - HEADERS: \"Content-Type: application/json\" - HTTPMETHOD: POST 5. Save the End Point External System Navigate to Integration -> External System and open up the 'PLUSITRIRIGA' external system that was previously set up. Associate the Publish Channel and Enterprise Services to the External System Add a new row in Publish Channel with the newly created PLUSIMXSR and link the PLUSISREQ End Point as well Add two new rows with the newly created Enterprise Services. Make sure both are enabled 4. Create a relationship in the SR object Go to DB Config -> SR object -> Relationships. Add a 'New Row' and enter the following values: Field Name Value Relationship PLUSIREQCLASS Child Object ALNDOMAIN Where Clause domainid= 'PLUSIREQCLASS' and value=:PLUSIreqclassid Remarks Relationship to PLUSIREQCLASS Alndomain 5. Application Designer Go to System Configuration -> Platform Configuration -> Application Designer Search for 'SR' Switch to the Service Request Tab and scroll down to the Service Request Details section At the top, click the icon labeled Control Palette and add a Multipart Textbox at the top of the right section. Add these values within the properties of the Multipart Textbox. Be sure that the PLUSIREQCLASSID Attribute is taken from the TICKET Object. Field Name Value Attribute PLUSIREQCLASSID Attribute for Part 2 PLUSIREQCLASS.DESCRIPTION Lookup VALUELIST Input Mode for Part 2 Readonly Click 'Save Definition' after the changes are added. AppConnect The configuration of AppConnect from the previous code pattern should provide the 'mxtririga' and 'trimaximo' accounts within AppConnect needed for the flows to work properly. Download and import the .yaml files for 'PLUSIMXServiceReq2TRI' and 'PLUSITRIReqClass2MX' and keep the urls handy for a later step. Use the following table for the parameters: Parameter Name Value mxUrl http://[host]:[port]/meaweb/esqueue/PLUSITRIRIGA/PLUSIMXSR triUrl http://[host]:[port]/oslc/so/triAPICServiceRequestCF mxDomain PLUSIREQCLASS TRIRIGA Populate the domain created in the Maximo pre-requisites Go to Tools -> System Setup and select Integration Object under the Integration heading Select triRequestClass - APIC - HTTP Post from the table or create it if it is not present. Fill in the required sections: Field Name Value Name triRequestClass - APIC- HTTP Post Scheme Http Post Direction Outbound Post Type JSON Http URL [the PLUSITRIReqClass2MX url from AppConnect with the correct parameters outlined in the AppConnect section] Request Method POST Content-Type application/json **If the AppConnect instance is based on cloud, include the api key in the Headers. If the instance is on-prem, include your basic authorization in UserName and Password Once the correct values are filled in, click Execute at the top of the window. The process will take a few minutes since there is a large amount of files, but once it is completed you can check that the batch processed correctly under the specified domain. Filter To filter the request from TRIRIGA to Maximo, update filter in the triAPICServiceRequest - OSLC - Outbound query to trigger for selected Request Classes. Current filter is set to Request Class not null. (Optional) Step 1. Sync a Person to TRIRIGA ***This step is optional. If you are starting from scratch, run this flow to sync the person in both systems. If data is already aligned and present, move on to the next step A service request needs a member of the TRIRIGA organization on both Maximo and TRIRIGA. Accomplish this by creating a person record that will be requesting the SR and assign them to the TRIRIGA org. The PLUSIMXPerson2TRI flow can help with this. Navigate to Administration -> Resources -> Person and click on 'New Person' under 'Common Activities' on the left side of the screen. Create this new Person record with a 'Site' field of TRIMAIN as well as a primary email. Save the record and the MXPerson2TRI flow will sync the data into TRIRIGA and this user will be used in Step 2. Step 2. Create a Service Request Maximo to TRIRIGA Go to Service Desk -> Service Request and click on the blue plus sign to create a new service request. Assign a user to Reported By and Affected Person (the user created in Step 1 should be used here). From here, a request classification needs to be selected and the value and description will populate in. Click 'Save Service Request' and the flow should fire. TRIRIGA to Maximo Go to Requests -> Manage Requests -> Electrical & Lighting and click the 'Add' button on the top right. Fill in the required fields and click 'Submit' at the top right of the newly opened window. The flow should fire upon submission. Troubleshooting Common Errors and their resolutions: Maximo Common errors found in the Maximo system Error Cause 401: Bad Request This usually means an aspect of the request was not sent correctly- double check what is being sent as well as the flow in AppConnect to make sure everything is correct and running. AppConnect The best way to troubleshoot with AppConnect is to use the logging function. While the flow is stopped, add a 'Log' node into the flow from the 'Toolbox' tab. This will allow mapping of any field to the 'Logging' section of the application. Select Info for the Log level and then map the field that needs debugging. In this example the Request Object has been mapped to see what is being sent through the flow. Click the icon to the right of the Message Detail filed to map the desired field. The Log node will compile the message and read out here: Diagnose the response that shows up in this section to learn what might be causing the issue. TRIRIGA Common errors found in the TRIRIGA system Error Cause ERROR: Requested For Does not Exist No People record exists with the triIdTX value mentioned in triRequestedForTX field of the payload ERROR: Requested By Does not Exist No People record exists with the triIdTX value mentioned in triRequestedByTX field of the payload ERROR: Building Does not Exist No Building record exists with the triNameTX value mentioned in triBuildingTX field of the payload ERROR: Request Class Does not Exist No Request Class record exists with the triNameTX value mentioned in triRequestClassCL field of the payload ERROR: Organization Does not Exist No Organization record exists with the triPathTX value mentioned in triCustomerOrgTX field of the payload ERROR: Service Request Does not Exist No Service Request record exists with the triIdTX value mentioned in triExternalReferenceTX field of the payload","title":"Service Request Integration"},{"location":"service-request/#service-request-integration","text":"","title":"Service Request Integration"},{"location":"service-request/#summary","text":"Enable automated synchronization of Service Request data from IBM Maximo to IBM TRIRIGA or vice versa.","title":"Summary"},{"location":"service-request/#description","text":"In this code pattern, learn how to synchronize a Service Request created in Maximo with TRIRIGA using an AppConnect Designer flow. When a Service Request is created in Maximo Asset Management, it triggers the flow to populate the request in TRIRIGA. (There is also a flow that works in the reverse direction, that works in a similar way.) App Connect sends a request with the new information through the flow towards the target system (TRIRIGA). A JSON Parser sifts through the request and converts it to an object. This object from the JSON Parser goes through Steps 5-8. The data from the object is mapped to the corresponding fields in the target application (TRIRIGA). The newly mapped data is sent to the target application (TRIRIGA) where the request is then created. This record is then validated with the original application (Maximo Asset Management) via another Post request. An ID is created within the original application (Maximo Asset Management). At the end of this process, a Service Request can be created within Maximo and sent to TRIRIGA and vice versa.","title":"Description"},{"location":"service-request/#pre-requisites","text":"This configuration assumes the completion of the pre-requisites and steps outlined in the Maximo <-> TRIRIGA code pattern. See here for those steps.","title":"Pre-requisites"},{"location":"service-request/#maximo","text":"Within Maximo, some initial changes to the database and Service Request application need to be completed in order for the integration to work properly. Errors may arise if these steps are not completed.","title":"Maximo"},{"location":"service-request/#1-create-a-domain-that-will-link-to-an-attribute-on-the-ticket-table","text":"Field Name Value Domain PLUSIREQCLASS Description Tririga service request class Domain Type ALN Data Type ALN Length 10 This domain will need to be populated in order to send a service request out of Maximo. This will be completed in a later step.","title":"1. Create a Domain that will link to an attribute on the Ticket table."},{"location":"service-request/#2-head-to-database-configuration-and-search-for-the-ticket-object","text":"Go to 'Attributes' and create a new row: Field Name Value Attribute PLUSIREQCLASSID Description TRIRIGA request class of value Type ALN Length 10 Required No Domain Select the PLUSIREQCLASS Domain from the previous step ** Make sure the length of this attribute has the same length as the domain that is linked Save the attribute. Apply the configuration changes to the database by switching on Admin mode and Apply Database Configuration","title":"2. Head to Database Configuration and search for the 'Ticket' object."},{"location":"service-request/#3-configure-the-publish-channel-enterprise-service-end-point-and-external-system","text":"","title":"3. Configure the Publish Channel, Enterprise Service, End Point, and External System"},{"location":"service-request/#publish-channel","text":"Navigate to Integration -> Publish Channels 1. Search for 'MXSRInterface' under the Publish Channel field. Click on the channel and from the left side of the screen select 'Duplicate Publish Channel' 2. Rename the channel PLUSIMXSR 3. Click on 'Enable Event Listener' on the left side under More Actions 4. Make sure Publish JSON and Retain MBO's are checked, the Operation should default to Publish and the Adapter should default to MAXIMO. 5. Click 'Save Publish Channel' on the left under Common Actions","title":"Publish Channel"},{"location":"service-request/#enterprise-service","text":"Navigate to Integration -> Enterprise Services and click on the blue plus button at the top of the page 1. Under the System name fill in PLUSIMXSR and in the Description fill in \"SERVICE REQUEST\" 2. Select 'MXSR' under Object Structure which will populate the Object Structure Sub-Records table 3. Click 'Save Enterprise Service' on the left under Common Actions Repeat this sequence for PLUSISRDOMAIN. In Description fill in \"Service Request class records from Tririga\" and select 'MXDOMAIN' for the Object Structure.","title":"Enterprise Service"},{"location":"service-request/#end-point","text":"Navigate to Integration -> End Points and click on the blue plus bitton at the top of the page 1. Under End Point fill in PLUSISREQ and in the Description fill in \"AppConnect SERVICE REQUEST outbound to TRIRIGA\" 2. Select 'HTTP' for Handler 3. Click on 'Save End Point' on the left side under More Actions which will populate the Properties for the End Point 4. Until the flows have a destination url, we can only fill in certain fields: - HEADERS: \"Content-Type: application/json\" - HTTPMETHOD: POST 5. Save the End Point","title":"End Point"},{"location":"service-request/#external-system","text":"Navigate to Integration -> External System and open up the 'PLUSITRIRIGA' external system that was previously set up. Associate the Publish Channel and Enterprise Services to the External System Add a new row in Publish Channel with the newly created PLUSIMXSR and link the PLUSISREQ End Point as well Add two new rows with the newly created Enterprise Services. Make sure both are enabled","title":"External System"},{"location":"service-request/#4-create-a-relationship-in-the-sr-object","text":"Go to DB Config -> SR object -> Relationships. Add a 'New Row' and enter the following values: Field Name Value Relationship PLUSIREQCLASS Child Object ALNDOMAIN Where Clause domainid= 'PLUSIREQCLASS' and value=:PLUSIreqclassid Remarks Relationship to PLUSIREQCLASS Alndomain","title":"4. Create a relationship in the SR object"},{"location":"service-request/#5-application-designer","text":"Go to System Configuration -> Platform Configuration -> Application Designer Search for 'SR' Switch to the Service Request Tab and scroll down to the Service Request Details section At the top, click the icon labeled Control Palette and add a Multipart Textbox at the top of the right section. Add these values within the properties of the Multipart Textbox. Be sure that the PLUSIREQCLASSID Attribute is taken from the TICKET Object. Field Name Value Attribute PLUSIREQCLASSID Attribute for Part 2 PLUSIREQCLASS.DESCRIPTION Lookup VALUELIST Input Mode for Part 2 Readonly Click 'Save Definition' after the changes are added.","title":"5. Application Designer"},{"location":"service-request/#appconnect","text":"The configuration of AppConnect from the previous code pattern should provide the 'mxtririga' and 'trimaximo' accounts within AppConnect needed for the flows to work properly. Download and import the .yaml files for 'PLUSIMXServiceReq2TRI' and 'PLUSITRIReqClass2MX' and keep the urls handy for a later step. Use the following table for the parameters: Parameter Name Value mxUrl http://[host]:[port]/meaweb/esqueue/PLUSITRIRIGA/PLUSIMXSR triUrl http://[host]:[port]/oslc/so/triAPICServiceRequestCF mxDomain PLUSIREQCLASS","title":"AppConnect"},{"location":"service-request/#tririga","text":"","title":"TRIRIGA"},{"location":"service-request/#populate-the-domain-created-in-the-maximo-pre-requisites","text":"Go to Tools -> System Setup and select Integration Object under the Integration heading Select triRequestClass - APIC - HTTP Post from the table or create it if it is not present. Fill in the required sections: Field Name Value Name triRequestClass - APIC- HTTP Post Scheme Http Post Direction Outbound Post Type JSON Http URL [the PLUSITRIReqClass2MX url from AppConnect with the correct parameters outlined in the AppConnect section] Request Method POST Content-Type application/json **If the AppConnect instance is based on cloud, include the api key in the Headers. If the instance is on-prem, include your basic authorization in UserName and Password Once the correct values are filled in, click Execute at the top of the window. The process will take a few minutes since there is a large amount of files, but once it is completed you can check that the batch processed correctly under the specified domain.","title":"Populate the domain created in the Maximo pre-requisites"},{"location":"service-request/#filter","text":"To filter the request from TRIRIGA to Maximo, update filter in the triAPICServiceRequest - OSLC - Outbound query to trigger for selected Request Classes. Current filter is set to Request Class not null.","title":"Filter"},{"location":"service-request/#optional-step-1-sync-a-person-to-tririga","text":"***This step is optional. If you are starting from scratch, run this flow to sync the person in both systems. If data is already aligned and present, move on to the next step A service request needs a member of the TRIRIGA organization on both Maximo and TRIRIGA. Accomplish this by creating a person record that will be requesting the SR and assign them to the TRIRIGA org. The PLUSIMXPerson2TRI flow can help with this. Navigate to Administration -> Resources -> Person and click on 'New Person' under 'Common Activities' on the left side of the screen. Create this new Person record with a 'Site' field of TRIMAIN as well as a primary email. Save the record and the MXPerson2TRI flow will sync the data into TRIRIGA and this user will be used in Step 2.","title":"(Optional) Step 1. Sync a Person to TRIRIGA"},{"location":"service-request/#step-2-create-a-service-request","text":"","title":"Step 2. Create a Service Request"},{"location":"service-request/#maximo-to-tririga","text":"Go to Service Desk -> Service Request and click on the blue plus sign to create a new service request. Assign a user to Reported By and Affected Person (the user created in Step 1 should be used here). From here, a request classification needs to be selected and the value and description will populate in. Click 'Save Service Request' and the flow should fire.","title":"Maximo to TRIRIGA"},{"location":"service-request/#tririga-to-maximo","text":"Go to Requests -> Manage Requests -> Electrical & Lighting and click the 'Add' button on the top right. Fill in the required fields and click 'Submit' at the top right of the newly opened window. The flow should fire upon submission.","title":"TRIRIGA to Maximo"},{"location":"service-request/#troubleshooting","text":"Common Errors and their resolutions:","title":"Troubleshooting"},{"location":"service-request/#maximo_1","text":"Common errors found in the Maximo system Error Cause 401: Bad Request This usually means an aspect of the request was not sent correctly- double check what is being sent as well as the flow in AppConnect to make sure everything is correct and running.","title":"Maximo"},{"location":"service-request/#appconnect_1","text":"The best way to troubleshoot with AppConnect is to use the logging function. While the flow is stopped, add a 'Log' node into the flow from the 'Toolbox' tab. This will allow mapping of any field to the 'Logging' section of the application. Select Info for the Log level and then map the field that needs debugging. In this example the Request Object has been mapped to see what is being sent through the flow. Click the icon to the right of the Message Detail filed to map the desired field. The Log node will compile the message and read out here: Diagnose the response that shows up in this section to learn what might be causing the issue.","title":"AppConnect"},{"location":"service-request/#tririga_1","text":"Common errors found in the TRIRIGA system Error Cause ERROR: Requested For Does not Exist No People record exists with the triIdTX value mentioned in triRequestedForTX field of the payload ERROR: Requested By Does not Exist No People record exists with the triIdTX value mentioned in triRequestedByTX field of the payload ERROR: Building Does not Exist No Building record exists with the triNameTX value mentioned in triBuildingTX field of the payload ERROR: Request Class Does not Exist No Request Class record exists with the triNameTX value mentioned in triRequestClassCL field of the payload ERROR: Organization Does not Exist No Organization record exists with the triPathTX value mentioned in triCustomerOrgTX field of the payload ERROR: Service Request Does not Exist No Service Request record exists with the triIdTX value mentioned in triExternalReferenceTX field of the payload","title":"TRIRIGA"},{"location":"tas-envizi-index/","text":"IBM TAS Connector for Envizi Overview Enable on-demand and scheduled synchronization of location data between TRIRIGA and Envizi systems. Prerequisites This integration requires running instances of TRIRIGA, App Connect, and Envizi. Tririga Configuration Before AppConnect flow is configured, OM package needs to be installed on the Tririga instance. Follow the documentation here for detailed instructions. AppConnect Configuration Note: IBM Cloud AppConnect Professional or Enterprise is needed to run this flow. Note: The names in the screenshots are generic, the elements in this integration will not have the same names during setup. Adding Accounts Before importing the flow to AppConnect, add Accounts for SFTP and HTTP connectors. While adding the HTTP connector account, include credentials for the Tririga user which can consume the OSLC API. Navigate to Catalog section of the AppConnect instance In the \"Search application\" field, type name of the connector. If the AppConnect instance does not have an account for the connector, click on \"Connect\" to create a new account Else, open the account selection drop down, and click on \"Add a new account ...\" Enter the necessary details for the connector For SFTP, it will be the SFTP server and user account. For HTTP, it will be the Authentication Key or username and password needed for Tririga. Click on Connect From the account selection drop down, select the newly created account. e.g., The default name will be Account 2 if Account 1 is already present Click on the kebab menu (three dots) and select \"Rename Account\" Enter an account name and click on \"Rename Account\". This name can now be used by the connector in the flow. Importing the flow Open the Dashboard of the AppConnect instance Click on the \"New\" button and select \"Import Flow\" Browse to the flow's YAML file and click on \"Import\" The flow will now be imported and opened. Configuring the flow to use the right accounts When importing a flow, it is important to check if the flow is using the right accounts for the different connectors. Click on \"Edit Flow\" See if the connectors are using the right accounts. To change the account for any connector, select the connector and click on the dropdown icon next to the Account's name Select the account name to use from the list Configuring the Scheduler Click on the \"Scheduler\" node Configure the schedule as needed","title":"Overview"},{"location":"tas-envizi-index/#ibm-tas-connector-for-envizi","text":"","title":"IBM TAS Connector for Envizi"},{"location":"tas-envizi-index/#overview","text":"Enable on-demand and scheduled synchronization of location data between TRIRIGA and Envizi systems.","title":"Overview"},{"location":"tas-envizi-index/#prerequisites","text":"This integration requires running instances of TRIRIGA, App Connect, and Envizi.","title":"Prerequisites"},{"location":"tas-envizi-index/#tririga-configuration","text":"Before AppConnect flow is configured, OM package needs to be installed on the Tririga instance. Follow the documentation here for detailed instructions.","title":"Tririga Configuration"},{"location":"tas-envizi-index/#appconnect-configuration","text":"Note: IBM Cloud AppConnect Professional or Enterprise is needed to run this flow. Note: The names in the screenshots are generic, the elements in this integration will not have the same names during setup.","title":"AppConnect Configuration"},{"location":"tas-envizi-index/#adding-accounts","text":"Before importing the flow to AppConnect, add Accounts for SFTP and HTTP connectors. While adding the HTTP connector account, include credentials for the Tririga user which can consume the OSLC API. Navigate to Catalog section of the AppConnect instance In the \"Search application\" field, type name of the connector. If the AppConnect instance does not have an account for the connector, click on \"Connect\" to create a new account Else, open the account selection drop down, and click on \"Add a new account ...\" Enter the necessary details for the connector For SFTP, it will be the SFTP server and user account. For HTTP, it will be the Authentication Key or username and password needed for Tririga. Click on Connect From the account selection drop down, select the newly created account. e.g., The default name will be Account 2 if Account 1 is already present Click on the kebab menu (three dots) and select \"Rename Account\" Enter an account name and click on \"Rename Account\". This name can now be used by the connector in the flow.","title":"Adding Accounts"},{"location":"tas-envizi-index/#importing-the-flow","text":"Open the Dashboard of the AppConnect instance Click on the \"New\" button and select \"Import Flow\" Browse to the flow's YAML file and click on \"Import\" The flow will now be imported and opened.","title":"Importing the flow"},{"location":"tas-envizi-index/#configuring-the-flow-to-use-the-right-accounts","text":"When importing a flow, it is important to check if the flow is using the right accounts for the different connectors. Click on \"Edit Flow\" See if the connectors are using the right accounts. To change the account for any connector, select the connector and click on the dropdown icon next to the Account's name Select the account name to use from the list","title":"Configuring the flow to use the right accounts"},{"location":"tas-envizi-index/#configuring-the-scheduler","text":"Click on the \"Scheduler\" node Configure the schedule as needed","title":"Configuring the Scheduler"},{"location":"tririga-configuration/","text":"Tririga Configuration for Envizi Integration Table of Contents Import OM Package Data Modeler Form Builder Security Manager Workflow Builder Optional: Patch Helper My Reports/OSLC How to Use This solution adds four fields that hold the group name values and the path for the integration. It also makes sure that the payload is sent when there is an update. Import OM Package Import the most recent OM Package into the Tririga instance. Go to Tools -> Administration -> Object Migration and select 'New Import Package' to begin the import process. Here are the manual changes that need to be done: Data Modeler Go to Tools -> Builder Tools -> Data Modeler and using the Object Browser navigate to Location->triBuilding. Revise the BO and add four fields: cstEnviziParentOneTX, cstEnviziParentTwoTX, cstEnviziParentThreeTX and cstEnviziGroupNamePathTX Name and Label should be the following: Name Label cstEnviziParentOneTX Envizi Group 1 cstEnviziParentTwoTX Envizi Group 2 cstEnviziParentThreeTX Envizi Group 3 cstEnviziGroupNamePathTX Envizi Path After entering these values, click 'Publish' to publish the BO Form Builder Under Tools -> Builder Tools -> Form Builder, click on the Location module on the left side of the screen and then click on triBuilding. Revise the triBuilding form by clicking 'Revise' in the top right corner of the pop-up In the Navigation pane on the left side of the screen, click on 'Add Tab' and enter \"cstEnvizi\" as the 'Name'. Click Apply Select this new tab and click on 'Add Section' Enter \"cstEnviziDetails\" as the 'Name' and \"Envizi Details\" as the 'Label'. Click 'Apply'. Now click on the newly created Section and select 'Add Field'. Select each of the four created business objects from the previous step as fields under \"Envizi Details\". Select 'cstEnviziGroupNamePathTX' and modify 'Start Row' to 3 and 'Col Span' to 2 on the properties window. Mark this field as \"ReadOnly\" and click 'Apply'. The form should look like this: Click on triBuilding on the left panel and then click on 'Sort Tab'. Move the 'cstEnvizi' tab to the second position and click 'Apply' Publish the form Security Manager Go to Tools -> Administration -> Security Manager This application sets who can and cannot access this newly created tab. Click on the desired group, and navigate to the 'Access' tab On this tab select Location -> triBuilding -> cstEnvizi Choose the access level for the group and 'Save' Workflow Builder Three Workflows will need to be edited. 1. Go to Tools -> Builder Tools -> Workflow Builder. Select Location -> triBuilding. Create a new Workflow name \"cst - triBuilding - Update Envizi path\" This Workflow should look like this: Add to the workflow with the following steps: Create the first 'Switch Condition' and enter the following condition: Create two 'Modify Tasks' and place them on either side of the switch. The 'Modify Parent One' task should be on the left and have this mapping: The 'Set Blank' task is the other condition of the first switch and it should have this mapping: The second switch should flow from the 'Modify Parent One' task and have the following condition: Create the 'Modify Parent Two' task and give it this mapping: The third switch should flow from 'Modify Parent Two' and have the following condition: The 'Modify Parent Three' task should have this mapping: Publish \"cst - triBuilding - Update Envizi path\" workflow 2. Within the Location object, search for the existing Workflow \"triBuilding - Synchronous - Permanent Save Validation\". Revise this workflow and after Call Module Level Validation add a new WF call to \"cst - triBuilding - Update Envizi path\" like displayed below: Publish the workflow 3. Navigate to Data Utilities -> cstEnviziUtility on the left panel and revise Workflow cst - cstEnviziUtility - Synchronous - Update Buildings with Group Names This workflow has some mapping missing. Update the three Modify Tasks: Open Modify Group Name1 modify task and enter the following Open Modify Group Name2 modify task and enter the following Open Modify Group Name3 modify task and enter the following Publish this workflow Optional Step This is an optional step if there are old records that need to be updated with the patch helper. Modify the Workflow \"cst - triPatchHelper - Update All Envizi location fields\", located on triHelper -> triPatchHelper Revise the Workflow and modify the following tasks: Modify Parent One task(if a custom value is desired, set it on these mappings): Modify Parent Two task(if a custom value is desired, set it on these mappings): Modify Parent TwoPath task: Modify Parent Three task(if a custom value is desired, set it on these mappings): Modify Parent Three Path task: SetBlank: Set Parent Two and Three Blank: Set Parent Three Blank: Save and publish the workflow My Reports and OSLC Go to My Reports and navigate to 'System Reports'. Add those four new fields to the existing query \"triAPICBuilding - OSLC -- Outbound\" and save the report. Open Tools -> System Setup -> Integration -> OSLC Resource manager and search for \"triAPICOutboundBuildingRS\". On this resource, add the four new fields either individually or using 'Import all Fields' How to use This tool will allow user to make changes on this new Envizi group name fields, but existing records must be considered too. To populate those records, there is a patch helper workflow that can handle that. This workflow by default adds the groupnames with the value from Hierarchy Path. So for example, if the HierarchyPath is \"Location/NorthAmerica/USA/Texas/Dallas\", then the group names will be: Name Value Envizi Group 1 Dallas Envizi Group 2 Texas Envizi Group 3 USA Envizi Path USA/Texas/Dallas You can customize this values by changing workflow \"cst - triPatchHelper - Update All Envizi location fields\" like described before Also, you can filter to change only the desired records by changing query \"cst - triBuilding - Query - Get All Buildings for envizi\". The list of buildings displayed on this query will be the list of buildings that the patch helper will modify To run this patch helper, go To Administration -> Data Integration to run patch helper. Upload a file using triNameTx = Envizi TXT file should have this content After that the records will be populated with the initial values defined. Please note that Patch helpers can be executed only once. To run this patch helper one more time, Envizi will need to be removed from the list that can be found using the query `\"triPatchHelper - Display - All\" There are two possible scenarios to use this solution: Modify only one record a. Open the building to change and click on tab Envizi. Modify the values and save the record Modify multiple records a. Go to My Reports, and run report \"cst - cstEnviziUtility - QUERY - Update Envizi GroupNames\" b. Click on 'Add' c. Define the values for each groupName and filter the buildings to apply on the Buildings section d. Select the buildings and click on Create. e. Click on Mass Update","title":"Tririga Configuration for Envizi Integration"},{"location":"tririga-configuration/#tririga-configuration-for-envizi-integration","text":"","title":"Tririga Configuration for Envizi Integration"},{"location":"tririga-configuration/#table-of-contents","text":"Import OM Package Data Modeler Form Builder Security Manager Workflow Builder Optional: Patch Helper My Reports/OSLC How to Use This solution adds four fields that hold the group name values and the path for the integration. It also makes sure that the payload is sent when there is an update.","title":"Table of Contents"},{"location":"tririga-configuration/#import-om-package","text":"Import the most recent OM Package into the Tririga instance. Go to Tools -> Administration -> Object Migration and select 'New Import Package' to begin the import process. Here are the manual changes that need to be done:","title":"Import OM Package"},{"location":"tririga-configuration/#data-modeler","text":"Go to Tools -> Builder Tools -> Data Modeler and using the Object Browser navigate to Location->triBuilding. Revise the BO and add four fields: cstEnviziParentOneTX, cstEnviziParentTwoTX, cstEnviziParentThreeTX and cstEnviziGroupNamePathTX Name and Label should be the following: Name Label cstEnviziParentOneTX Envizi Group 1 cstEnviziParentTwoTX Envizi Group 2 cstEnviziParentThreeTX Envizi Group 3 cstEnviziGroupNamePathTX Envizi Path After entering these values, click 'Publish' to publish the BO","title":"Data Modeler"},{"location":"tririga-configuration/#form-builder","text":"Under Tools -> Builder Tools -> Form Builder, click on the Location module on the left side of the screen and then click on triBuilding. Revise the triBuilding form by clicking 'Revise' in the top right corner of the pop-up In the Navigation pane on the left side of the screen, click on 'Add Tab' and enter \"cstEnvizi\" as the 'Name'. Click Apply Select this new tab and click on 'Add Section' Enter \"cstEnviziDetails\" as the 'Name' and \"Envizi Details\" as the 'Label'. Click 'Apply'. Now click on the newly created Section and select 'Add Field'. Select each of the four created business objects from the previous step as fields under \"Envizi Details\". Select 'cstEnviziGroupNamePathTX' and modify 'Start Row' to 3 and 'Col Span' to 2 on the properties window. Mark this field as \"ReadOnly\" and click 'Apply'. The form should look like this: Click on triBuilding on the left panel and then click on 'Sort Tab'. Move the 'cstEnvizi' tab to the second position and click 'Apply' Publish the form","title":"Form Builder"},{"location":"tririga-configuration/#security-manager","text":"Go to Tools -> Administration -> Security Manager This application sets who can and cannot access this newly created tab. Click on the desired group, and navigate to the 'Access' tab On this tab select Location -> triBuilding -> cstEnvizi Choose the access level for the group and 'Save'","title":"Security Manager"},{"location":"tririga-configuration/#workflow-builder","text":"Three Workflows will need to be edited. 1. Go to Tools -> Builder Tools -> Workflow Builder. Select Location -> triBuilding. Create a new Workflow name \"cst - triBuilding - Update Envizi path\" This Workflow should look like this: Add to the workflow with the following steps: Create the first 'Switch Condition' and enter the following condition: Create two 'Modify Tasks' and place them on either side of the switch. The 'Modify Parent One' task should be on the left and have this mapping: The 'Set Blank' task is the other condition of the first switch and it should have this mapping: The second switch should flow from the 'Modify Parent One' task and have the following condition: Create the 'Modify Parent Two' task and give it this mapping: The third switch should flow from 'Modify Parent Two' and have the following condition: The 'Modify Parent Three' task should have this mapping: Publish \"cst - triBuilding - Update Envizi path\" workflow 2. Within the Location object, search for the existing Workflow \"triBuilding - Synchronous - Permanent Save Validation\". Revise this workflow and after Call Module Level Validation add a new WF call to \"cst - triBuilding - Update Envizi path\" like displayed below: Publish the workflow 3. Navigate to Data Utilities -> cstEnviziUtility on the left panel and revise Workflow cst - cstEnviziUtility - Synchronous - Update Buildings with Group Names This workflow has some mapping missing. Update the three Modify Tasks: Open Modify Group Name1 modify task and enter the following Open Modify Group Name2 modify task and enter the following Open Modify Group Name3 modify task and enter the following Publish this workflow","title":"Workflow Builder"},{"location":"tririga-configuration/#optional-step","text":"This is an optional step if there are old records that need to be updated with the patch helper. Modify the Workflow \"cst - triPatchHelper - Update All Envizi location fields\", located on triHelper -> triPatchHelper Revise the Workflow and modify the following tasks: Modify Parent One task(if a custom value is desired, set it on these mappings): Modify Parent Two task(if a custom value is desired, set it on these mappings): Modify Parent TwoPath task: Modify Parent Three task(if a custom value is desired, set it on these mappings): Modify Parent Three Path task: SetBlank: Set Parent Two and Three Blank: Set Parent Three Blank: Save and publish the workflow","title":"Optional Step"},{"location":"tririga-configuration/#my-reports-and-oslc","text":"Go to My Reports and navigate to 'System Reports'. Add those four new fields to the existing query \"triAPICBuilding - OSLC -- Outbound\" and save the report. Open Tools -> System Setup -> Integration -> OSLC Resource manager and search for \"triAPICOutboundBuildingRS\". On this resource, add the four new fields either individually or using 'Import all Fields'","title":"My Reports and OSLC"},{"location":"tririga-configuration/#how-to-use","text":"This tool will allow user to make changes on this new Envizi group name fields, but existing records must be considered too. To populate those records, there is a patch helper workflow that can handle that. This workflow by default adds the groupnames with the value from Hierarchy Path. So for example, if the HierarchyPath is \"Location/NorthAmerica/USA/Texas/Dallas\", then the group names will be: Name Value Envizi Group 1 Dallas Envizi Group 2 Texas Envizi Group 3 USA Envizi Path USA/Texas/Dallas You can customize this values by changing workflow \"cst - triPatchHelper - Update All Envizi location fields\" like described before Also, you can filter to change only the desired records by changing query \"cst - triBuilding - Query - Get All Buildings for envizi\". The list of buildings displayed on this query will be the list of buildings that the patch helper will modify To run this patch helper, go To Administration -> Data Integration to run patch helper. Upload a file using triNameTx = Envizi TXT file should have this content After that the records will be populated with the initial values defined. Please note that Patch helpers can be executed only once. To run this patch helper one more time, Envizi will need to be removed from the list that can be found using the query `\"triPatchHelper - Display - All\" There are two possible scenarios to use this solution: Modify only one record a. Open the building to change and click on tab Envizi. Modify the values and save the record Modify multiple records a. Go to My Reports, and run report \"cst - cstEnviziUtility - QUERY - Update Envizi GroupNames\" b. Click on 'Add' c. Define the values for each groupName and filter the buildings to apply on the Buildings section d. Select the buildings and click on Create. e. Click on Mass Update","title":"How to use"},{"location":"tririga-envizi/","text":"Tririga - Envizi integration Using the flows Flows included in this integration: TririgaBuildings_Always_On TririgaBuildings_On_Demand This integration comes with two types of flows: On-demand Flow This flow is for the initial sync or to sync data that was added/updated between specific dates. This flow is meant to be executed just once whenever needed and then stopped. To use this flow, the following parameters in \"Set variable\" node need to be configured: Variable > config > OverrideFromDate: The start timestamp of the window between which the data will be pulled from. The date must be specified in ISO 8601 format. e.g., 2022-06-26T23:09:30-07:00 where -07:00 represents timezone offset of UTC-07:00 hours Variable > config > OverrideToDate: The end timestamp of the window between which the data will be pulled from. The date must be specified in ISO 8601 format. e.g., 2022-06-26T23:09:30-07:00 where -07:00 represents timezone offset of UTC-07:00 hours Always-On Flow This flow is to keep syncing the data after the initial sync This flow is meant to be kept running This flow will only sync the data that has been added or updated after its previous execution event. e.g., If the flow executes at 2 PM and it's previous execution was at 1 PM, the flow will pull data that has been added or updated after 1 PM. Configuring the Flow Parameters Click on the \"Set variable\" node In Variable > config > customer, enter the value provided by Envizi In Variable > config > triURL, enter URL for the Tririga instance e.g., https://example.com:9080 Starting and Stopping the flow If using AppConnect Dashboard, Click on the kebab menu (three dots) on the flow's tile. If inside the flow, Click on the kebab menu (three dots) on top right of the screen. Click on \"Start API\" or \"Stop API\" depending on which action is desired. Note: If the flow is not running, AppConnect will give Error 404 on the API call. Post-Setup Instructions The Envizi implementation team will support the next steps of the integration by provisioning the file transfer details, enabling Envizi data connectors and validating the Envizi configuration ready to receive the data flow. Please reach out to the primary contact at Envizi who can help coordinate next steps.","title":"IBM Tririga Application Suite Connector for Envizi"},{"location":"tririga-envizi/#tririga-envizi-integration","text":"","title":"Tririga - Envizi integration"},{"location":"tririga-envizi/#using-the-flows","text":"Flows included in this integration: TririgaBuildings_Always_On TririgaBuildings_On_Demand This integration comes with two types of flows:","title":"Using the flows"},{"location":"tririga-envizi/#on-demand-flow","text":"This flow is for the initial sync or to sync data that was added/updated between specific dates. This flow is meant to be executed just once whenever needed and then stopped. To use this flow, the following parameters in \"Set variable\" node need to be configured: Variable > config > OverrideFromDate: The start timestamp of the window between which the data will be pulled from. The date must be specified in ISO 8601 format. e.g., 2022-06-26T23:09:30-07:00 where -07:00 represents timezone offset of UTC-07:00 hours Variable > config > OverrideToDate: The end timestamp of the window between which the data will be pulled from. The date must be specified in ISO 8601 format. e.g., 2022-06-26T23:09:30-07:00 where -07:00 represents timezone offset of UTC-07:00 hours","title":"On-demand Flow"},{"location":"tririga-envizi/#always-on-flow","text":"This flow is to keep syncing the data after the initial sync This flow is meant to be kept running This flow will only sync the data that has been added or updated after its previous execution event. e.g., If the flow executes at 2 PM and it's previous execution was at 1 PM, the flow will pull data that has been added or updated after 1 PM.","title":"Always-On Flow"},{"location":"tririga-envizi/#configuring-the-flow-parameters","text":"Click on the \"Set variable\" node In Variable > config > customer, enter the value provided by Envizi In Variable > config > triURL, enter URL for the Tririga instance e.g., https://example.com:9080","title":"Configuring the Flow Parameters"},{"location":"tririga-envizi/#starting-and-stopping-the-flow","text":"If using AppConnect Dashboard, Click on the kebab menu (three dots) on the flow's tile. If inside the flow, Click on the kebab menu (three dots) on top right of the screen. Click on \"Start API\" or \"Stop API\" depending on which action is desired. Note: If the flow is not running, AppConnect will give Error 404 on the API call.","title":"Starting and Stopping the flow"},{"location":"tririga-envizi/#post-setup-instructions","text":"The Envizi implementation team will support the next steps of the integration by provisioning the file transfer details, enabling Envizi data connectors and validating the Envizi configuration ready to receive the data flow. Please reach out to the primary contact at Envizi who can help coordinate next steps.","title":"Post-Setup Instructions"},{"location":"work-order/","text":"Work Order Integration Summary Enable automated synchronization of Work Order data from IBM Maximo to IBM TRIRIGA or vice versa. Description In this code pattern, learn how to synchronize a Work Order created in Maximo with TRIRIGA using an AppConnect Designer flow. When a Work Order is created in Maximo Asset Management, it triggers the flow to populate the request in TRIRIGA. (There is also a flow that works in the reverse direction, that works in a similar way.) App Connect sends a request with the new information through the flow towards the target system (TRIRIGA). A JSON Parser sifts through the request and converts it to an object. This object from the JSON Parser goes through Steps 5-8. The data from the object is mapped to the corresponding fields in the target application (TRIRIGA). The newly mapped data is sent to the target application (TRIRIGA) where the request is then created. This record is then validated with the original application (Maximo Asset Management) via another Post request. An ID is created within the original application (Maximo Asset Management). At the end of this process, a Work Order can be created within Maximo and sent to TRIRIGA and vice versa. Pre-requisites This configuration assumes the completion of the pre-requisites and steps outlined in the Maximo <-> TRIRIGA code pattern. See here for those steps. Maximo Within Maximo, some initial changes to the database and Work Order application need to be completed in order for the integration to work properly. Errors may arise if these steps are not completed. 1. Create a Domain that will link to an attribute on the WORKORDER table. Domain Description Domain Type Data Type Length PLUSILOCPATH Tririga location path details ALN ALN 10 PLUSIORG Primary organization path ALN ALN 10 These domain will need to be populated in order to send a Work Order out of Maximo. This will be completed in a later step. 2. Search for the 'WORKORDER' object in Database Configuration. Go to 'Attributes' and create a new row: Attribute Description Type Length Required Domain PLUSILOCPATH Tririga location path details ALN ALN No Select the PLUSILOCPATH Domain from the previous step PLUSIORGPATH Primary organization path ALN ALN No Select the PLUSIORG Domain from the previous step Make sure the length of this attribute has the same length as the domain that is linked Save the attribute. Apply the configuration changes to the database by switching on Admin mode and Apply Database Configuration 3. Configure the Publish Channel, Enterprise Service, End Point, and External System Publish Channel Navigate to Integration -> Publish Channels 1. Search for 'MXWOInterface' under the Publish Channel field. Click on the channel and from the left side of the screen select 'Duplicate Publish Channel' 2. Rename the channel PLUSIMXWO 3. Click on 'Enable Event Listener' on the left side under More Actions 4. Make sure Publish JSON and Retain MBO's are checked, the Operation should default to Publish and the Adapter should default to MAXIMO. 5. Click 'Save Publish Channel' on the left under Common Actions Enterprise Service Navigate to Integration -> Enterprise Services and click on the blue plus button at the top of the page 1. Under the System name fill in PLUSIWO and in the Description fill in \"Work Order\" 2. Select 'MXWO' under Object Structure which will populate the Object Structure Sub-Records table 3. Click 'Save Enterprise Service' on the left under Common Actions Repeat this sequence for PLUSIORGDOMAIN and PLUSILOCDOMAIN. In Description fill in \"Organization records from Tririga\" & \"Location path records from Tririga\" respectively and select 'MXDOMAIN' for both Object Structures. End Point Navigate to Integration -> End Points and click on the blue plus bitton at the top of the page 1. Under End Point fill in PLUSIWO and in the Description fill in \"AppConnect Work Order outbound to TRIRIGA\" 2. Select 'HTTP' for Handler 3. Click on 'Save End Point' on the left side under More Actions which will populate the Properties for the End Point 4. Until the flows have a destination url, we can only fill in certain fields: - HEADERS: \"Content-Type: application/json\" - HTTPMETHOD: POST 5. Save the End Point External System Navigate to Integration -> External System and open up the 'PLUSITRIRIGA' external system that was previously set up. Associate the Publish Channel and Enterprise Services to the External System Add a new row in Publish Channel with the newly created PLUSIMXWO and link the PLUSIWO End Point as well Add three new rows with the newly created Enterprise Services. Make sure all are enabled 4. Create a relationship in the WORKORDER object Go to DB Config -> WORKORDER object -> Relationships. Add a 'New Row' and enter the following values: Relationship Child Object Where Clause Remarks PLUSILOCATIONPATH ALNDOMAIN domainid='PLUSILOCPATH' and value=:plusilocpath Relationship to PLUSILOCPATH Alndomain PLUSIORGANIZATIONPATH ALNDOMAIN domainid='PLUSIORG' and value=:plusiorgpath Relationship to PLUSIORGPATH Alndomain 5. Application Designer Go to System Configuration -> Platform Configuration -> Application Designer Search for 'WOTRACK' Switch to the Work Order Tab and scroll down to the Work Order Details section At the top, click the icon labeled Control Palette and drag the respective controls into the first main section on the right of the screen. Add these values within the properties of the control. Be sure that the PLUSIREQCLASSID Attribute is taken from the WORKORDER Object. Type of Control Label Attribute Attribute for Part 2 ( If Multipart Textbox ) Lookup Input Mode for Part 2 ( If Multipart Textbox ) Multipart Textbox Tririga Location Path PLUSILOCPATH PLUSILOCATIONPATH.DESCRIPTION VALUELIST Readonly Multipart Textbox Tririga Primary Organization PLUSIORGPATH PLUSIORGANIZATIONPATH.DESCRIPTION VALUELIST Readonly Textbox External Ref ID EXTERNALREFID ( From the WorkOrder Object ) N/A N/A N/A Click 'Save Definition' after the changes are added. AppConnect The configuration of AppConnect from the previous code pattern should provide the 'mxtririga' and 'trimaximo' accounts within AppConnect needed for the flows to work properly. Download and import the .yaml files and keep the urls handy for a later step. Use the following table for the parameters of the flows: Parameter Name Value mxUrl http://[host]:[port]/meaweb/esqueue/PLUSITRIRIGA/PLUSIMXWO triUrl http://[host]:[port]/oslc/so/triAPICWorkTaskCF mxDomain PLUSILOCPATH ( For Loc Path flow ) / PLUSIORGPATH ( For Org Path flow ) TRIRIGA Populate the domains created in the Maximo pre-requisites Go to Tools -> System Setup and select Integration Object under the Integration heading Select Organization - APIC - HTTP Post from the table. Fill in the required sections: Field Name Value Http URL [the PLUSITRIOrgPath2MX url from AppConnect with the correct parameters outlined in the AppConnect section] Request Method POST Content-Type application/json If the AppConnect instance is based on cloud, include the api key in the Headers. If the instance is on-prem, include your basic authorization in UserName and Password Once the correct values are filled in, click Execute at the top of the window. The process will take a few minutes since there is a large amount of files, but once it is completed you can check that the batch processed correctly under the specified domain. Repeat the process with triBuilding , triProperty , & triFloor using the PLUSITRILocPath2MX url and parameters. Verify the data is in sync by checking the corresponding Domain in Maximo. The populated table should look like this: Step 1. Create a Work Order Maximo to TRIRIGA Go to Work Orders -> Work Order Tracking and click on the blue plus sign to create a new Work Order. Input the desired name/number of the WO along with the description and assign the corresponding Primary Org and Location Path. Click 'Save Work Order' and the flow should fire. The flow also supports the cost calculation of associated actuals within a Work Order. Costs can only be transacted against a Work Order with a valid GL Account. Once the proper GL Account is associated, navigate to the 'Actuals' tab within the desired Work Order to assign costs. The supported actuals are 'Labor', 'Materials', 'Services', and 'Tools'. A. Labor Select the correct Labor record to associate with the Work Order. Enter in the required Start and End Time fields and 'Save' the Work Order. The flow will update the Tririga application with the correct cost associated with the Labor based on the time entered. B. Materials Select the correct Material record to associate with the Work Order. Enter in the required 'Storeroom' field and 'Save' the Work Order. The flow will update the Tririga application with the correct cost associated with the Material. C. Services The Service actual will only populate if a PO is received, and the PO has a Service line associated with the Work Order. In order to initialize this, create a new Purchasing Order and add a new PO Line. Select 'Service' as the Line Type and enter the Line Cost. Associate the desired WO for this Service to be charged and approve the PO. In the 'Receiving' application, select the approved PO and switch to the 'Service Receipts' tab at the top. Click on 'Select Ordered Services', select the created Service, and click 'Save Receipt' on the left-hand side of the screen. The Service will then appear as an actual in both Maximo and Tririga via the flow. D. Tools Select the correct Tool record to associate with the Work Order. Enter in the required Bin field and 'Save' the Work Order. The flow will update the Tririga application with the correct cost associated with the Material. A full breakdown of costs can be found by going to View -> Costs from the left side of the screen under 'More Actions' TRIRIGA to Maximo Go to Tasks -> Manage Tasks -> Work Tasks and click the 'Add' button on the top right. Fill in the required fields and click 'Submit' at the top right of the newly opened window. The flow should fire upon submission. Troubleshooting Common Errors and their resolutions: Maximo Common errors found in the Maximo system Error Cause 401: Bad Request This usually means an aspect of the request was not sent correctly- double check what is being sent as well as the flow in AppConnect to make sure everything is correct and running. AppConnect The best way to troubleshoot with AppConnect is to use the logging function. While the flow is stopped, add a 'Log' node into the flow from the 'Toolbox' tab. This will allow mapping of any field to the 'Logging' section of the application. Select Info for the Log level and then map the field that needs debugging. In this example the Request Object has been mapped to see what is being sent through the flow. Click the icon to the right of the Message Detail filed to map the desired field. The Log node will compile the message and read out here: Diagnose the response that shows up in this section to learn what might be causing the issue. TRIRIGA Common errors found in the TRIRIGA system Error Cause ERROR: Requested For Does not Exist No People record exists with the triIdTX value mentioned in triRequestedForTX field of the payload ERROR: Building Does not Exist No Building record exists with the triNameTX value mentioned in triBuildingTX field of the payload ERROR: Location Does not Exist No Location record exists with the triNameTX value mentioned in triParentLocationTX field of the payload ERROR: Organization Does not Exist No Organization record exists with the triPathTX value mentioned in triCustomerOrgTX field of the payload","title":"Work Order Integration"},{"location":"work-order/#work-order-integration","text":"","title":"Work Order Integration"},{"location":"work-order/#summary","text":"Enable automated synchronization of Work Order data from IBM Maximo to IBM TRIRIGA or vice versa.","title":"Summary"},{"location":"work-order/#description","text":"In this code pattern, learn how to synchronize a Work Order created in Maximo with TRIRIGA using an AppConnect Designer flow. When a Work Order is created in Maximo Asset Management, it triggers the flow to populate the request in TRIRIGA. (There is also a flow that works in the reverse direction, that works in a similar way.) App Connect sends a request with the new information through the flow towards the target system (TRIRIGA). A JSON Parser sifts through the request and converts it to an object. This object from the JSON Parser goes through Steps 5-8. The data from the object is mapped to the corresponding fields in the target application (TRIRIGA). The newly mapped data is sent to the target application (TRIRIGA) where the request is then created. This record is then validated with the original application (Maximo Asset Management) via another Post request. An ID is created within the original application (Maximo Asset Management). At the end of this process, a Work Order can be created within Maximo and sent to TRIRIGA and vice versa.","title":"Description"},{"location":"work-order/#pre-requisites","text":"This configuration assumes the completion of the pre-requisites and steps outlined in the Maximo <-> TRIRIGA code pattern. See here for those steps.","title":"Pre-requisites"},{"location":"work-order/#maximo","text":"Within Maximo, some initial changes to the database and Work Order application need to be completed in order for the integration to work properly. Errors may arise if these steps are not completed.","title":"Maximo"},{"location":"work-order/#1-create-a-domain-that-will-link-to-an-attribute-on-the-workorder-table","text":"Domain Description Domain Type Data Type Length PLUSILOCPATH Tririga location path details ALN ALN 10 PLUSIORG Primary organization path ALN ALN 10 These domain will need to be populated in order to send a Work Order out of Maximo. This will be completed in a later step.","title":"1. Create a Domain that will link to an attribute on the WORKORDER table."},{"location":"work-order/#2-search-for-the-workorder-object-in-database-configuration","text":"Go to 'Attributes' and create a new row: Attribute Description Type Length Required Domain PLUSILOCPATH Tririga location path details ALN ALN No Select the PLUSILOCPATH Domain from the previous step PLUSIORGPATH Primary organization path ALN ALN No Select the PLUSIORG Domain from the previous step Make sure the length of this attribute has the same length as the domain that is linked Save the attribute. Apply the configuration changes to the database by switching on Admin mode and Apply Database Configuration","title":"2. Search for the 'WORKORDER' object in Database Configuration."},{"location":"work-order/#3-configure-the-publish-channel-enterprise-service-end-point-and-external-system","text":"","title":"3. Configure the Publish Channel, Enterprise Service, End Point, and External System"},{"location":"work-order/#publish-channel","text":"Navigate to Integration -> Publish Channels 1. Search for 'MXWOInterface' under the Publish Channel field. Click on the channel and from the left side of the screen select 'Duplicate Publish Channel' 2. Rename the channel PLUSIMXWO 3. Click on 'Enable Event Listener' on the left side under More Actions 4. Make sure Publish JSON and Retain MBO's are checked, the Operation should default to Publish and the Adapter should default to MAXIMO. 5. Click 'Save Publish Channel' on the left under Common Actions","title":"Publish Channel"},{"location":"work-order/#enterprise-service","text":"Navigate to Integration -> Enterprise Services and click on the blue plus button at the top of the page 1. Under the System name fill in PLUSIWO and in the Description fill in \"Work Order\" 2. Select 'MXWO' under Object Structure which will populate the Object Structure Sub-Records table 3. Click 'Save Enterprise Service' on the left under Common Actions Repeat this sequence for PLUSIORGDOMAIN and PLUSILOCDOMAIN. In Description fill in \"Organization records from Tririga\" & \"Location path records from Tririga\" respectively and select 'MXDOMAIN' for both Object Structures.","title":"Enterprise Service"},{"location":"work-order/#end-point","text":"Navigate to Integration -> End Points and click on the blue plus bitton at the top of the page 1. Under End Point fill in PLUSIWO and in the Description fill in \"AppConnect Work Order outbound to TRIRIGA\" 2. Select 'HTTP' for Handler 3. Click on 'Save End Point' on the left side under More Actions which will populate the Properties for the End Point 4. Until the flows have a destination url, we can only fill in certain fields: - HEADERS: \"Content-Type: application/json\" - HTTPMETHOD: POST 5. Save the End Point","title":"End Point"},{"location":"work-order/#external-system","text":"Navigate to Integration -> External System and open up the 'PLUSITRIRIGA' external system that was previously set up. Associate the Publish Channel and Enterprise Services to the External System Add a new row in Publish Channel with the newly created PLUSIMXWO and link the PLUSIWO End Point as well Add three new rows with the newly created Enterprise Services. Make sure all are enabled","title":"External System"},{"location":"work-order/#4-create-a-relationship-in-the-workorder-object","text":"Go to DB Config -> WORKORDER object -> Relationships. Add a 'New Row' and enter the following values: Relationship Child Object Where Clause Remarks PLUSILOCATIONPATH ALNDOMAIN domainid='PLUSILOCPATH' and value=:plusilocpath Relationship to PLUSILOCPATH Alndomain PLUSIORGANIZATIONPATH ALNDOMAIN domainid='PLUSIORG' and value=:plusiorgpath Relationship to PLUSIORGPATH Alndomain","title":"4. Create a relationship in the WORKORDER object"},{"location":"work-order/#5-application-designer","text":"Go to System Configuration -> Platform Configuration -> Application Designer Search for 'WOTRACK' Switch to the Work Order Tab and scroll down to the Work Order Details section At the top, click the icon labeled Control Palette and drag the respective controls into the first main section on the right of the screen. Add these values within the properties of the control. Be sure that the PLUSIREQCLASSID Attribute is taken from the WORKORDER Object. Type of Control Label Attribute Attribute for Part 2 ( If Multipart Textbox ) Lookup Input Mode for Part 2 ( If Multipart Textbox ) Multipart Textbox Tririga Location Path PLUSILOCPATH PLUSILOCATIONPATH.DESCRIPTION VALUELIST Readonly Multipart Textbox Tririga Primary Organization PLUSIORGPATH PLUSIORGANIZATIONPATH.DESCRIPTION VALUELIST Readonly Textbox External Ref ID EXTERNALREFID ( From the WorkOrder Object ) N/A N/A N/A Click 'Save Definition' after the changes are added.","title":"5. Application Designer"},{"location":"work-order/#appconnect","text":"The configuration of AppConnect from the previous code pattern should provide the 'mxtririga' and 'trimaximo' accounts within AppConnect needed for the flows to work properly. Download and import the .yaml files and keep the urls handy for a later step. Use the following table for the parameters of the flows: Parameter Name Value mxUrl http://[host]:[port]/meaweb/esqueue/PLUSITRIRIGA/PLUSIMXWO triUrl http://[host]:[port]/oslc/so/triAPICWorkTaskCF mxDomain PLUSILOCPATH ( For Loc Path flow ) / PLUSIORGPATH ( For Org Path flow )","title":"AppConnect"},{"location":"work-order/#tririga","text":"Populate the domains created in the Maximo pre-requisites Go to Tools -> System Setup and select Integration Object under the Integration heading Select Organization - APIC - HTTP Post from the table. Fill in the required sections: Field Name Value Http URL [the PLUSITRIOrgPath2MX url from AppConnect with the correct parameters outlined in the AppConnect section] Request Method POST Content-Type application/json If the AppConnect instance is based on cloud, include the api key in the Headers. If the instance is on-prem, include your basic authorization in UserName and Password Once the correct values are filled in, click Execute at the top of the window. The process will take a few minutes since there is a large amount of files, but once it is completed you can check that the batch processed correctly under the specified domain. Repeat the process with triBuilding , triProperty , & triFloor using the PLUSITRILocPath2MX url and parameters. Verify the data is in sync by checking the corresponding Domain in Maximo. The populated table should look like this:","title":"TRIRIGA"},{"location":"work-order/#step-1-create-a-work-order","text":"","title":"Step 1. Create a Work Order"},{"location":"work-order/#maximo-to-tririga","text":"Go to Work Orders -> Work Order Tracking and click on the blue plus sign to create a new Work Order. Input the desired name/number of the WO along with the description and assign the corresponding Primary Org and Location Path. Click 'Save Work Order' and the flow should fire. The flow also supports the cost calculation of associated actuals within a Work Order. Costs can only be transacted against a Work Order with a valid GL Account. Once the proper GL Account is associated, navigate to the 'Actuals' tab within the desired Work Order to assign costs. The supported actuals are 'Labor', 'Materials', 'Services', and 'Tools'.","title":"Maximo to TRIRIGA"},{"location":"work-order/#a-labor","text":"Select the correct Labor record to associate with the Work Order. Enter in the required Start and End Time fields and 'Save' the Work Order. The flow will update the Tririga application with the correct cost associated with the Labor based on the time entered.","title":"A. Labor"},{"location":"work-order/#b-materials","text":"Select the correct Material record to associate with the Work Order. Enter in the required 'Storeroom' field and 'Save' the Work Order. The flow will update the Tririga application with the correct cost associated with the Material.","title":"B. Materials"},{"location":"work-order/#c-services","text":"The Service actual will only populate if a PO is received, and the PO has a Service line associated with the Work Order. In order to initialize this, create a new Purchasing Order and add a new PO Line. Select 'Service' as the Line Type and enter the Line Cost. Associate the desired WO for this Service to be charged and approve the PO. In the 'Receiving' application, select the approved PO and switch to the 'Service Receipts' tab at the top. Click on 'Select Ordered Services', select the created Service, and click 'Save Receipt' on the left-hand side of the screen. The Service will then appear as an actual in both Maximo and Tririga via the flow.","title":"C. Services"},{"location":"work-order/#d-tools","text":"Select the correct Tool record to associate with the Work Order. Enter in the required Bin field and 'Save' the Work Order. The flow will update the Tririga application with the correct cost associated with the Material. A full breakdown of costs can be found by going to View -> Costs from the left side of the screen under 'More Actions'","title":"D. Tools"},{"location":"work-order/#tririga-to-maximo","text":"Go to Tasks -> Manage Tasks -> Work Tasks and click the 'Add' button on the top right. Fill in the required fields and click 'Submit' at the top right of the newly opened window. The flow should fire upon submission.","title":"TRIRIGA to Maximo"},{"location":"work-order/#troubleshooting","text":"Common Errors and their resolutions:","title":"Troubleshooting"},{"location":"work-order/#maximo_1","text":"Common errors found in the Maximo system Error Cause 401: Bad Request This usually means an aspect of the request was not sent correctly- double check what is being sent as well as the flow in AppConnect to make sure everything is correct and running.","title":"Maximo"},{"location":"work-order/#appconnect_1","text":"The best way to troubleshoot with AppConnect is to use the logging function. While the flow is stopped, add a 'Log' node into the flow from the 'Toolbox' tab. This will allow mapping of any field to the 'Logging' section of the application. Select Info for the Log level and then map the field that needs debugging. In this example the Request Object has been mapped to see what is being sent through the flow. Click the icon to the right of the Message Detail filed to map the desired field. The Log node will compile the message and read out here: Diagnose the response that shows up in this section to learn what might be causing the issue.","title":"AppConnect"},{"location":"work-order/#tririga_1","text":"Common errors found in the TRIRIGA system Error Cause ERROR: Requested For Does not Exist No People record exists with the triIdTX value mentioned in triRequestedForTX field of the payload ERROR: Building Does not Exist No Building record exists with the triNameTX value mentioned in triBuildingTX field of the payload ERROR: Location Does not Exist No Location record exists with the triNameTX value mentioned in triParentLocationTX field of the payload ERROR: Organization Does not Exist No Organization record exists with the triPathTX value mentioned in triCustomerOrgTX field of the payload","title":"TRIRIGA"}]}